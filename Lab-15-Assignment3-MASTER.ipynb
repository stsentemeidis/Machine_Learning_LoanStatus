{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 16 Assignment 3 - Group Assignment - Group O-1-7\n",
    "\n",
    "When creating ML models, the concept of efficiency has three sides:\n",
    "1. The time dedicated by the analyst to build the model\n",
    "2. The computer time and resources needed by the final model\n",
    "3. The accuracy of the final model\n",
    "\n",
    "Efficiency is a combination of all\n",
    "\n",
    "In this assignment, you are asked to be efficient. Spark is the best tool to build models over massive datasets\n",
    "\n",
    "If you need to create Spark+Python Machine Learning models that \"run fast\" on the  cluster, you must avoid using Python code or working with RRD+python. Try to use  the already existing methods that do what you need (do not reinvent the wheel).\n",
    "\n",
    "Therefore try to use the implemented object+methods inside the Spark SQL and ML modules. They are very fast, because it is compiled Java/Scala code. Try to use: DataFrames, Feature Transfomers, Estimators, Pipelines, GridSearch, CV, ...\n",
    "\n",
    "For this assignment, you are asked to create a classification model that:\n",
    "1. Uses the variables in the dataset (train.csv) to predict label \"loan_status\"\n",
    "2. Write a python scripts that:\n",
    "    - Reads the \"train.csv\" and \"test.csv\" files, transform and select variables as you wish.\n",
    "    - Train/fit your model using the \"train.csv\".\n",
    "    - Predict your model on the \"test.csv\" ( you should generate a file with your predictions).\n",
    "    - I will use a different test dataset (with the true loan_status).\n",
    "\n",
    "Your work will be evaluated under the following scoring schema\n",
    "- (40%) ETL process\n",
    "- (40%) Model train process\n",
    "- (10%) Code Readability \n",
    "- (10%) AUC on the test set (at least 50%)\n",
    "\n",
    "Enjoy it and best of luck!!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Assignment is based on kaggle competition https://www.kaggle.com/c/loan-default-prediction from where a sub-dataset has been taken.\n",
    "\n",
    "### File Description\n",
    "**train.csv** - the training set (to use for building a model)\n",
    "\n",
    "**test.csv** - the test set (to use for applying predictings)\n",
    "\n",
    "**sample_submission.csv** - a template for the submission file\n",
    "\n",
    "### Data Description (contained in LendingClub_DataDescription.csv)\n",
    "**ID**: A unique LC assigned ID for the loan listing.\n",
    "\n",
    "**loan_amnt**: The listed amount of the loan applied for by the borrower. If at some point in time, the credit department reduces the loan amount, then it will be reflected in this value.\n",
    "\n",
    "**loan_status**: Current status of the loan (**Target**: 1 = Charged Off, 0 = Fully Paid).\n",
    "\n",
    "**term**: The number of payments on the loan. Values are in months and can be either 36 or 60.\n",
    "\n",
    "**int_rate**: Interest Rate on the loan.\n",
    "\n",
    "**installment**: The monthly payment owed by the borrower if the loan originates.\n",
    "\n",
    "**emp_length**: Employment length in years. Possible values are between 0 and 10 where 0 means less than one year and 10 means ten or more years.\n",
    "\n",
    "**home_ownership**: The home ownership status provided by the borrower during registration. Our values are: OTHER/NONE, MORTGAGE, OWN, RENT.\n",
    "\n",
    "**annual_inc**: The self-reported annual income provided by the borrower during registration.\n",
    "\n",
    "**purpose**: A category provided by the borrower for the loan request.\n",
    "\n",
    "**title**: The loan title provided by the borrower.\n",
    "\n",
    "**STATE**: The state provided by the borrower in the loan application.\n",
    "\n",
    "**delinq_2yrs**: The number of 30+ days past-due incidences of delinquency in the borrower's credit file for the past 2 years.\n",
    "\n",
    "**revol_bal**: Total credit revolving balance.\n",
    "\n",
    "**revol_util**: Revolving line utilization rate, or the amount of credit the borrower is using relative to all available revolving credit.\n",
    "\n",
    "**total_pymnt**: Indicates total payment at the end of the loan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ['SPARK_HOME'] = \"/Users/stavrostsentemeidis/Desktop/Install_Spark/spark-2.3.2-bin-hadoop2.7/\"\n",
    "\n",
    "# Create a variable for our root path\n",
    "SPARK_HOME = os.environ['SPARK_HOME']\n",
    "\n",
    "#Add the following paths to the system path. Please check your installation\n",
    "#to make sure that these zip files actually exist. The names might change\n",
    "#as versions change.\n",
    "sys.path.insert(0,os.path.join(SPARK_HOME,\"python\"))\n",
    "sys.path.insert(0,os.path.join(SPARK_HOME,\"python\",\"lib\"))\n",
    "sys.path.insert(0,os.path.join(SPARK_HOME,\"python\",\"lib\",\"pyspark.zip\"))\n",
    "sys.path.insert(0,os.path.join(SPARK_HOME,\"python\",\"lib\",\"py4j-0.10.7-src.zip\"))\n",
    "\n",
    "#Initialize SparkSession and SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import avg\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.functions import isnan, when, count\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.classification import RandomForestClassificationModel, RandomForestClassifier\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator, CrossValidatorModel\n",
    "from pyspark.ml.param import Params\n",
    "from pyspark.ml import Pipeline, PipelineModel\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import OneHotEncoderEstimator\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "from pyspark.ml.feature import MinMaxScaler\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "#Create a Spark Session\n",
    "MySparkSession = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(\"local[2]\") \\\n",
    "    .appName(\"MiPrimer\") \\\n",
    "    .config(\"spark.executor.memory\", \"6g\") \\\n",
    "    .config(\"spark.cores.max\",\"4\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "\n",
    "#Get the Spark Context from Spark Session    \n",
    "MySparkContext = MySparkSession.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading & Displaying Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "loanDF = MySparkSession.read.format('csv') \\\n",
    "                .option(\"inferSchema\", \"true\") \\\n",
    "                .option(\"delimiter\", \";\") \\\n",
    "                .option('header','true') \\\n",
    "                .load('../data/train.csv') \n",
    "\n",
    "testDF = MySparkSession.read.format('csv') \\\n",
    "                .option(\"inferSchema\", \"true\") \\\n",
    "                .option(\"delimiter\", \";\") \\\n",
    "                .option('header','true') \\\n",
    "                .load('../data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>term</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>emp_length</th>\n",
       "      <th>home_ownership</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>purpose</th>\n",
       "      <th>title</th>\n",
       "      <th>STATE</th>\n",
       "      <th>delinq_2yrs</th>\n",
       "      <th>revol_bal</th>\n",
       "      <th>revol_util</th>\n",
       "      <th>total_pymnt</th>\n",
       "      <th>loan_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2500</td>\n",
       "      <td>60 months</td>\n",
       "      <td>15.27%</td>\n",
       "      <td>59.83</td>\n",
       "      <td>&lt; 1 year</td>\n",
       "      <td>RENT</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>car</td>\n",
       "      <td>bike</td>\n",
       "      <td>GA</td>\n",
       "      <td>0</td>\n",
       "      <td>1687</td>\n",
       "      <td>0.094</td>\n",
       "      <td>1014.530000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>10000</td>\n",
       "      <td>36 months</td>\n",
       "      <td>13.49%</td>\n",
       "      <td>339.31</td>\n",
       "      <td>10+ years</td>\n",
       "      <td>RENT</td>\n",
       "      <td>49200.0</td>\n",
       "      <td>other</td>\n",
       "      <td>personel</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>5598</td>\n",
       "      <td>0.21</td>\n",
       "      <td>12231.890000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>3000</td>\n",
       "      <td>60 months</td>\n",
       "      <td>12.69%</td>\n",
       "      <td>67.79</td>\n",
       "      <td>1 year</td>\n",
       "      <td>RENT</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>other</td>\n",
       "      <td>Personal</td>\n",
       "      <td>OR</td>\n",
       "      <td>0</td>\n",
       "      <td>27783</td>\n",
       "      <td>0.539</td>\n",
       "      <td>4066.908161</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>5000</td>\n",
       "      <td>36 months</td>\n",
       "      <td>7.90%</td>\n",
       "      <td>156.46</td>\n",
       "      <td>3 years</td>\n",
       "      <td>RENT</td>\n",
       "      <td>36000.0</td>\n",
       "      <td>wedding</td>\n",
       "      <td>My wedding loan I promise to pay back</td>\n",
       "      <td>AZ</td>\n",
       "      <td>0</td>\n",
       "      <td>7963</td>\n",
       "      <td>0.283</td>\n",
       "      <td>5632.210000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>7000</td>\n",
       "      <td>60 months</td>\n",
       "      <td>15.96%</td>\n",
       "      <td>170.08</td>\n",
       "      <td>8 years</td>\n",
       "      <td>RENT</td>\n",
       "      <td>47004.0</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>Loan</td>\n",
       "      <td>NC</td>\n",
       "      <td>0</td>\n",
       "      <td>17726</td>\n",
       "      <td>0.856</td>\n",
       "      <td>10137.840010</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>3000</td>\n",
       "      <td>36 months</td>\n",
       "      <td>18.64%</td>\n",
       "      <td>109.43</td>\n",
       "      <td>9 years</td>\n",
       "      <td>RENT</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>car</td>\n",
       "      <td>Car Downpayment</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>8221</td>\n",
       "      <td>0.875</td>\n",
       "      <td>3939.135294</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>5375</td>\n",
       "      <td>60 months</td>\n",
       "      <td>12.69%</td>\n",
       "      <td>121.45</td>\n",
       "      <td>&lt; 1 year</td>\n",
       "      <td>RENT</td>\n",
       "      <td>15000.0</td>\n",
       "      <td>other</td>\n",
       "      <td>Building my credit history.</td>\n",
       "      <td>TX</td>\n",
       "      <td>0</td>\n",
       "      <td>9279</td>\n",
       "      <td>0.365</td>\n",
       "      <td>1484.590000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>11</td>\n",
       "      <td>6500</td>\n",
       "      <td>60 months</td>\n",
       "      <td>14.65%</td>\n",
       "      <td>153.45</td>\n",
       "      <td>5 years</td>\n",
       "      <td>OWN</td>\n",
       "      <td>72000.0</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>High intrest Consolidation</td>\n",
       "      <td>AZ</td>\n",
       "      <td>0</td>\n",
       "      <td>4032</td>\n",
       "      <td>0.206</td>\n",
       "      <td>7678.017673</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>12</td>\n",
       "      <td>12000</td>\n",
       "      <td>36 months</td>\n",
       "      <td>12.69%</td>\n",
       "      <td>402.54</td>\n",
       "      <td>10+ years</td>\n",
       "      <td>OWN</td>\n",
       "      <td>75000.0</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>Consolidation</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>23336</td>\n",
       "      <td>0.671</td>\n",
       "      <td>13947.989160</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>14</td>\n",
       "      <td>3000</td>\n",
       "      <td>36 months</td>\n",
       "      <td>9.91%</td>\n",
       "      <td>96.68</td>\n",
       "      <td>3 years</td>\n",
       "      <td>RENT</td>\n",
       "      <td>15000.0</td>\n",
       "      <td>credit_card</td>\n",
       "      <td>citicard fund</td>\n",
       "      <td>IL</td>\n",
       "      <td>0</td>\n",
       "      <td>7323</td>\n",
       "      <td>0.431</td>\n",
       "      <td>3480.269999</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  loan_amnt        term int_rate  installment emp_length home_ownership  \\\n",
       "0   2       2500   60 months   15.27%        59.83   < 1 year           RENT   \n",
       "1   4      10000   36 months   13.49%       339.31  10+ years           RENT   \n",
       "2   5       3000   60 months   12.69%        67.79     1 year           RENT   \n",
       "3   6       5000   36 months    7.90%       156.46    3 years           RENT   \n",
       "4   7       7000   60 months   15.96%       170.08    8 years           RENT   \n",
       "5   8       3000   36 months   18.64%       109.43    9 years           RENT   \n",
       "6  10       5375   60 months   12.69%       121.45   < 1 year           RENT   \n",
       "7  11       6500   60 months   14.65%       153.45    5 years            OWN   \n",
       "8  12      12000   36 months   12.69%       402.54  10+ years            OWN   \n",
       "9  14       3000   36 months    9.91%        96.68    3 years           RENT   \n",
       "\n",
       "   annual_inc             purpose                                  title  \\\n",
       "0     30000.0                 car                                   bike   \n",
       "1     49200.0               other                               personel   \n",
       "2     80000.0               other                               Personal   \n",
       "3     36000.0             wedding  My wedding loan I promise to pay back   \n",
       "4     47004.0  debt_consolidation                                   Loan   \n",
       "5     48000.0                 car                        Car Downpayment   \n",
       "6     15000.0               other            Building my credit history.   \n",
       "7     72000.0  debt_consolidation             High intrest Consolidation   \n",
       "8     75000.0  debt_consolidation                          Consolidation   \n",
       "9     15000.0         credit_card                          citicard fund   \n",
       "\n",
       "  STATE  delinq_2yrs  revol_bal revol_util   total_pymnt  loan_status  \n",
       "0    GA            0       1687      0.094   1014.530000            1  \n",
       "1    CA            0       5598       0.21  12231.890000            0  \n",
       "2    OR            0      27783      0.539   4066.908161            0  \n",
       "3    AZ            0       7963      0.283   5632.210000            0  \n",
       "4    NC            0      17726      0.856  10137.840010            0  \n",
       "5    CA            0       8221      0.875   3939.135294            0  \n",
       "6    TX            0       9279      0.365   1484.590000            1  \n",
       "7    AZ            0       4032      0.206   7678.017673            0  \n",
       "8    CA            0      23336      0.671  13947.989160            0  \n",
       "9    IL            0       7323      0.431   3480.269999            0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loanDF.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>term</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>emp_length</th>\n",
       "      <th>home_ownership</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>purpose</th>\n",
       "      <th>title</th>\n",
       "      <th>STATE</th>\n",
       "      <th>delinq_2yrs</th>\n",
       "      <th>revol_bal</th>\n",
       "      <th>revol_util</th>\n",
       "      <th>total_pymnt</th>\n",
       "      <th>loan_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>36 months</td>\n",
       "      <td>10.65%</td>\n",
       "      <td>162.87</td>\n",
       "      <td>10+ years</td>\n",
       "      <td>RENT</td>\n",
       "      <td>24000.0</td>\n",
       "      <td>credit_card</td>\n",
       "      <td>Computer</td>\n",
       "      <td>AZ</td>\n",
       "      <td>0</td>\n",
       "      <td>13648</td>\n",
       "      <td>0.84</td>\n",
       "      <td>5863.155187</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2400</td>\n",
       "      <td>36 months</td>\n",
       "      <td>15.96%</td>\n",
       "      <td>84.33</td>\n",
       "      <td>10+ years</td>\n",
       "      <td>RENT</td>\n",
       "      <td>12252.0</td>\n",
       "      <td>small_business</td>\n",
       "      <td>real estate business</td>\n",
       "      <td>IL</td>\n",
       "      <td>0</td>\n",
       "      <td>2956</td>\n",
       "      <td>0.99</td>\n",
       "      <td>3005.666844</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>5600</td>\n",
       "      <td>60 months</td>\n",
       "      <td>21.28%</td>\n",
       "      <td>152.39</td>\n",
       "      <td>4 years</td>\n",
       "      <td>OWN</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>small_business</td>\n",
       "      <td>Expand Business &amp; Buy Debt Portfolio</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>5210</td>\n",
       "      <td>0.33</td>\n",
       "      <td>647.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>9000</td>\n",
       "      <td>36 months</td>\n",
       "      <td>13.49%</td>\n",
       "      <td>305.38</td>\n",
       "      <td>&lt; 1 year</td>\n",
       "      <td>RENT</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>freedom</td>\n",
       "      <td>VA</td>\n",
       "      <td>0</td>\n",
       "      <td>10452</td>\n",
       "      <td>0.92</td>\n",
       "      <td>2277.320000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>10000</td>\n",
       "      <td>36 months</td>\n",
       "      <td>10.65%</td>\n",
       "      <td>325.74</td>\n",
       "      <td>3 years</td>\n",
       "      <td>RENT</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>other</td>\n",
       "      <td>Other Loan</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>11997</td>\n",
       "      <td>0.56</td>\n",
       "      <td>7471.990000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>18</td>\n",
       "      <td>3600</td>\n",
       "      <td>36 months</td>\n",
       "      <td>6.03%</td>\n",
       "      <td>109.57</td>\n",
       "      <td>10+ years</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>major_purchase</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>CT</td>\n",
       "      <td>0</td>\n",
       "      <td>22836</td>\n",
       "      <td>0.16</td>\n",
       "      <td>3785.271965</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>26</td>\n",
       "      <td>15000</td>\n",
       "      <td>36 months</td>\n",
       "      <td>9.91%</td>\n",
       "      <td>483.38</td>\n",
       "      <td>2 years</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>92000.0</td>\n",
       "      <td>credit_card</td>\n",
       "      <td>No more credit card debt!</td>\n",
       "      <td>IL</td>\n",
       "      <td>0</td>\n",
       "      <td>13707</td>\n",
       "      <td>0.94</td>\n",
       "      <td>15823.999050</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>27</td>\n",
       "      <td>15000</td>\n",
       "      <td>36 months</td>\n",
       "      <td>14.27%</td>\n",
       "      <td>514.64</td>\n",
       "      <td>9 years</td>\n",
       "      <td>RENT</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>consolidation</td>\n",
       "      <td>NY</td>\n",
       "      <td>0</td>\n",
       "      <td>5872</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>29</td>\n",
       "      <td>4000</td>\n",
       "      <td>36 months</td>\n",
       "      <td>11.71%</td>\n",
       "      <td>132.31</td>\n",
       "      <td>10+ years</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>106000.0</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>Debt Consolidation</td>\n",
       "      <td>FL</td>\n",
       "      <td>1</td>\n",
       "      <td>6110</td>\n",
       "      <td>0.38</td>\n",
       "      <td>4486.293519</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>31</td>\n",
       "      <td>4375</td>\n",
       "      <td>36 months</td>\n",
       "      <td>7.51%</td>\n",
       "      <td>136.11</td>\n",
       "      <td>7 years</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>17108.0</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>Debt Consolidation</td>\n",
       "      <td>NY</td>\n",
       "      <td>0</td>\n",
       "      <td>11210</td>\n",
       "      <td>0.87</td>\n",
       "      <td>4899.960000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  loan_amnt        term int_rate  installment emp_length home_ownership  \\\n",
       "0   1       5000   36 months   10.65%       162.87  10+ years           RENT   \n",
       "1   3       2400   36 months   15.96%        84.33  10+ years           RENT   \n",
       "2   9       5600   60 months   21.28%       152.39    4 years            OWN   \n",
       "3  13       9000   36 months   13.49%       305.38   < 1 year           RENT   \n",
       "4  15      10000   36 months   10.65%       325.74    3 years           RENT   \n",
       "5  18       3600   36 months    6.03%       109.57  10+ years       MORTGAGE   \n",
       "6  26      15000   36 months    9.91%       483.38    2 years       MORTGAGE   \n",
       "7  27      15000   36 months   14.27%       514.64    9 years           RENT   \n",
       "8  29       4000   36 months   11.71%       132.31  10+ years       MORTGAGE   \n",
       "9  31       4375   36 months    7.51%       136.11    7 years       MORTGAGE   \n",
       "\n",
       "   annual_inc             purpose                                 title STATE  \\\n",
       "0     24000.0         credit_card                              Computer    AZ   \n",
       "1     12252.0      small_business                  real estate business    IL   \n",
       "2     40000.0      small_business  Expand Business & Buy Debt Portfolio    CA   \n",
       "3     30000.0  debt_consolidation                               freedom    VA   \n",
       "4    100000.0               other                            Other Loan    CA   \n",
       "5    110000.0      major_purchase                               Holiday    CT   \n",
       "6     92000.0         credit_card             No more credit card debt!    IL   \n",
       "7     60000.0  debt_consolidation                         consolidation    NY   \n",
       "8    106000.0  debt_consolidation                    Debt Consolidation    FL   \n",
       "9     17108.0  debt_consolidation                    Debt Consolidation    NY   \n",
       "\n",
       "   delinq_2yrs  revol_bal revol_util   total_pymnt  loan_status  \n",
       "0            0      13648       0.84   5863.155187            1  \n",
       "1            0       2956       0.99   3005.666844            1  \n",
       "2            0       5210       0.33    647.500000            1  \n",
       "3            0      10452       0.92   2277.320000            1  \n",
       "4            0      11997       0.56   7471.990000            1  \n",
       "5            0      22836       0.16   3785.271965            1  \n",
       "6            0      13707       0.94  15823.999050            1  \n",
       "7            0       5872       0.58      0.000000            1  \n",
       "8            1       6110       0.38   4486.293519            1  \n",
       "9            0      11210       0.87   4899.960000            1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testDF.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA | Null Values | Cross Table Distribution | Covariances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary of Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ID: integer (nullable = true)\n",
      " |-- loan_amnt: integer (nullable = true)\n",
      " |-- term: string (nullable = true)\n",
      " |-- int_rate: string (nullable = true)\n",
      " |-- installment: double (nullable = true)\n",
      " |-- emp_length: string (nullable = true)\n",
      " |-- home_ownership: string (nullable = true)\n",
      " |-- annual_inc: double (nullable = true)\n",
      " |-- purpose: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- STATE: string (nullable = true)\n",
      " |-- delinq_2yrs: integer (nullable = true)\n",
      " |-- revol_bal: integer (nullable = true)\n",
      " |-- revol_util: string (nullable = true)\n",
      " |-- total_pymnt: double (nullable = true)\n",
      " |-- loan_status: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- ID: integer (nullable = true)\n",
      " |-- loan_amnt: integer (nullable = true)\n",
      " |-- term: string (nullable = true)\n",
      " |-- int_rate: string (nullable = true)\n",
      " |-- installment: double (nullable = true)\n",
      " |-- emp_length: string (nullable = true)\n",
      " |-- home_ownership: string (nullable = true)\n",
      " |-- annual_inc: double (nullable = true)\n",
      " |-- purpose: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- STATE: string (nullable = true)\n",
      " |-- delinq_2yrs: integer (nullable = true)\n",
      " |-- revol_bal: integer (nullable = true)\n",
      " |-- revol_util: string (nullable = true)\n",
      " |-- total_pymnt: double (nullable = true)\n",
      " |-- loan_status: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loanDF.printSchema()\n",
    "testDF.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Renaming | Describing | Changing Data Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loanDF = loanDF.withColumn('int_rate', regexp_replace('int_rate', '%', ''))\n",
    "loanDF = loanDF.withColumn('title', regexp_replace('title', '.', ''))\n",
    "loanDF = loanDF.withColumn(\"int_rate\", loanDF[\"int_rate\"].cast(\"decimal(10,0)\"))\n",
    "loanDF = loanDF.withColumn(\"revol_util\", loanDF[\"revol_util\"].cast(\"decimal(10,0)\"))\n",
    "\n",
    "testDF = testDF.withColumn('int_rate', regexp_replace('int_rate', '%', ''))\n",
    "testDF = testDF.withColumn('title', regexp_replace('title', '.', ''))\n",
    "testDF = testDF.withColumn(\"int_rate\", testDF[\"int_rate\"].cast(\"decimal(10,0)\"))\n",
    "testDF = testDF.withColumn(\"revol_util\", testDF[\"revol_util\"].cast(\"decimal(10,0)\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loanDF = loanDF.withColumnRenamed(\"ID\",\"id\")\n",
    "loanDF = loanDF.withColumnRenamed(\"loan_amnt\",\"loan_amount\")\n",
    "loanDF = loanDF.withColumnRenamed(\"term\",\"term\")\n",
    "loanDF = loanDF.withColumnRenamed(\"home_ownership\",\"home_ownership\")\n",
    "loanDF = loanDF.withColumnRenamed(\"int_rate\",\"interest_rate\")\n",
    "loanDF = loanDF.withColumnRenamed(\"installment\",\"monthly_payment\")\n",
    "loanDF = loanDF.withColumnRenamed(\"emp_length\",\"employment_time\")\n",
    "loanDF = loanDF.withColumnRenamed(\"delinq_2yrs\",\"deliquency_past_2years\")\n",
    "loanDF = loanDF.withColumnRenamed(\"revol_bal\",\"revolving_balance\")\n",
    "loanDF = loanDF.withColumnRenamed(\"revol_util\",\"revolving_utilization_rate\")\n",
    "loanDF = loanDF.withColumnRenamed(\"total_pymnt\",\"total_payment\")\n",
    "loanDF = loanDF.withColumnRenamed(\"purpose\",\"loan_purpose\")\n",
    "loanDF = loanDF.withColumnRenamed(\"annual_inc\",\"annual_income\")\n",
    "loanDF = loanDF.withColumnRenamed(\"STATE\",\"state\")\n",
    "loanDF = loanDF.withColumnRenamed(\"installment\",\"installment\")\n",
    "loanDF = loanDF.withColumnRenamed(\"loan_status\",\"loan_status\")\n",
    "\n",
    "\n",
    "testDF = testDF.withColumnRenamed(\"ID\",\"id\")\n",
    "testDF = testDF.withColumnRenamed(\"loan_amnt\",\"loan_amount\")\n",
    "testDF = testDF.withColumnRenamed(\"term\",\"term\")\n",
    "testDF = testDF.withColumnRenamed(\"home_ownership\",\"home_ownership\")\n",
    "testDF = testDF.withColumnRenamed(\"int_rate\",\"interest_rate\")\n",
    "testDF = testDF.withColumnRenamed(\"installment\",\"monthly_payment\")\n",
    "testDF = testDF.withColumnRenamed(\"emp_length\",\"employment_time\")\n",
    "testDF = testDF.withColumnRenamed(\"delinq_2yrs\",\"deliquency_past_2years\")\n",
    "testDF = testDF.withColumnRenamed(\"revol_bal\",\"revolving_balance\")\n",
    "testDF = testDF.withColumnRenamed(\"revol_util\",\"revolving_utilization_rate\")\n",
    "testDF = testDF.withColumnRenamed(\"total_pymnt\",\"total_payment\")\n",
    "testDF = testDF.withColumnRenamed(\"purpose\",\"loan_purpose\")\n",
    "testDF = testDF.withColumnRenamed(\"annual_inc\",\"annual_income\")\n",
    "testDF = testDF.withColumnRenamed(\"STATE\",\"state\")\n",
    "testDF = testDF.withColumnRenamed(\"installment\",\"installment\")\n",
    "testDF = testDF.withColumnRenamed(\"loan_status\",\"loan_status\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+----------+------------------+-----+---------------+--------------+\n",
      "|summary|       loan_amount|      term|     interest_rate|title|employment_time|home_ownership|\n",
      "+-------+------------------+----------+------------------+-----+---------------+--------------+\n",
      "|  count|             29755|     29755|             29755|28517|          29755|         29755|\n",
      "|   mean|11218.509494202655|      null|           12.0301| null|           null|          null|\n",
      "| stddev| 7431.662873498601|      null|3.7181574007403158| null|           null|          null|\n",
      "|    min|               500| 36 months|                 5|     |         1 year|      MORTGAGE|\n",
      "|    max|             35000| 60 months|                25|    ",
      "|            n/a|          RENT|\n",
      "+-------+------------------+----------+------------------+-----+---------------+--------------+\n",
      "\n",
      "+-------+----------------+------------+------------------+-----+----------------------+\n",
      "|summary|   annual_income|loan_purpose|   monthly_payment|state|deliquency_past_2years|\n",
      "+-------+----------------+------------+------------------+-----+----------------------+\n",
      "|  count|           29755|       28526|             29755|28516|                 28516|\n",
      "|   mean|69044.8235268022|        null|324.23834481599505| null|   0.14595314910927198|\n",
      "| stddev|66683.2408043667|        null|207.83497941026226| null|    0.4856901246589267|\n",
      "|    min|          4000.0|         car|             15.69|   AK|                     0|\n",
      "|    max|       6000000.0|     wedding|           1305.19|   WY|                     8|\n",
      "+-------+----------------+------------+------------------+-----+----------------------+\n",
      "\n",
      "+-------+------------------+--------------------------+------------------+-------------------+\n",
      "|summary| revolving_balance|revolving_utilization_rate|     total_payment|        loan_status|\n",
      "+-------+------------------+--------------------------+------------------+-------------------+\n",
      "|  count|             28516|                     27782|             28516|              29755|\n",
      "|   mean|13350.529071398512|                    0.5054|12143.791490200982|0.14199294236262813|\n",
      "| stddev| 15948.46067741967|        0.4999794563559059| 9085.146711349636| 0.3490487663481529|\n",
      "|    min|                 0|                         0|               0.0|                  0|\n",
      "|    max|            149588|                         1|       58886.47343|                  1|\n",
      "+-------+------------------+--------------------------+------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "numeric_df = ['loan_amount','interest_rate', 'monthly_payment','annual_income', 'deliquency_past_2years',\n",
    "              'total_payment','revolving_balance','revolving_utilization_rate']\n",
    "\n",
    "categorical_Df = ['term','employment_time', 'home_ownership', 'loan_purpose', 'title','state']\n",
    "\n",
    "loanDF.describe('loan_amount','term','interest_rate','title','employment_time','home_ownership').show()\n",
    "loanDF.describe('annual_income','loan_purpose','monthly_payment','state','deliquency_past_2years').show()\n",
    "loanDF.describe('revolving_balance','revolving_utilization_rate','total_payment','loan_status').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[summary: string, id: string, loan_amount: string, term: string, interest_rate: string, monthly_payment: string, employment_time: string, home_ownership: string, annual_income: string, loan_purpose: string, title: string, state: string, deliquency_past_2years: string, revolving_balance: string, revolving_utilization_rate: string, total_payment: string, loan_status: string]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(testDF.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29755\n",
      "10024\n"
     ]
    }
   ],
   "source": [
    "print(loanDF.count())\n",
    "print(testDF.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking Null Values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27773\n",
      "9116\n"
     ]
    }
   ],
   "source": [
    "remove_loanDF = loanDF.na.drop() \n",
    "remove_testDF = testDF.na.drop()  \n",
    "print(remove_loanDF.count())\n",
    "print(remove_testDF.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross Table Distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+---------+-------+-------+-------+-------+-------+-------+-------+-------+--------+---+\n",
      "|term_employment_time|1 year|10+ years|2 years|3 years|4 years|5 years|6 years|7 years|8 years|9 years|< 1 year|n/a|\n",
      "+--------------------+------+---------+-------+-------+-------+-------+-------+-------+-------+-------+--------+---+\n",
      "|           60 months|   497|     2284|    746|    748|    664|    724|    495|    389|    333|    268|     694|207|\n",
      "|           36 months|  1943|     4321|   2524|   2314|   1927|   1773|   1175|    943|    777|    672|    2752|585|\n",
      "+--------------------+------+---------+-------+-------+-------+-------+-------+-------+-------+-------+--------+---+\n",
      "\n",
      "+-------------------+--------+----+-----+----+-----+\n",
      "|term_home_ownership|MORTGAGE|NONE|OTHER| OWN| RENT|\n",
      "+-------------------+--------+----+-----+----+-----+\n",
      "|          60 months|    4315|   0|    0| 569| 3165|\n",
      "|          36 months|    8973|   3|   69|1703|10958|\n",
      "+-------------------+--------+----+-----+----+-----+\n",
      "\n",
      "+-----------------+---+-----------+------------------+-----------+----------------+-----+--------------+-------+------+----+-----+----------------+--------------+--------+-------+\n",
      "|term_loan_purpose|car|credit_card|debt_consolidation|educational|home_improvement|house|major_purchase|medical|moving|null|other|renewable_energy|small_business|vacation|wedding|\n",
      "+-----------------+---+-----------+------------------+-----------+----------------+-----+--------------+-------+------+----+-----+----------------+--------------+--------+-------+\n",
      "|        60 months|402|        750|              3976|         15|             649|   81|           328|    119|    68| 432|  616|              19|           406|      43|    145|\n",
      "|        36 months|719|       2944|              9429|        221|            1483|  195|          1258|    387|   344| 797| 2254|              49|           881|     228|    517|\n",
      "+-----------------+---+-----------+------------------+-----------+----------------+-----+--------------+-------+------+----+-----+----------------+--------------+--------+-------+\n",
      "\n",
      "+----------+---+---+---+---+----+---+---+---+---+----+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+----+---+---+---+---+---+---+---+---+----+---+---+---+---+---+---+---+----+\n",
      "|term_state| AK| AL| AR| AZ|  CA| CO| CT| DC| DE|  FL| GA| HI| IA| ID| IL| IN| KS| KY| LA| MA| MD| ME| MI| MN| MO| MS| MT| NC| NE| NH| NJ| NM| NV|  NY| OH| OK| OR| PA| RI| SC| SD| TN|  TX| UT| VA| VT| WA| WI| WV| WY|null|\n",
      "+----------+---+---+---+---+----+---+---+---+---+----+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+----+---+---+---+---+---+---+---+---+----+---+---+---+---+---+---+---+----+\n",
      "| 60 months| 12| 94| 49|186|1226|150|167| 30| 19| 529|297| 42|  0|  0|284|  0| 56| 81| 83|230|223|  0|167|121|135|  0| 21|194|  0| 32|368| 42|108| 689|262| 58| 84|299| 36|108| 11|  0| 494| 48|267| 10|145|100| 44| 14| 434|\n",
      "| 36 months| 39|227|123|465|3848|429|383|122| 56|1576|721| 83|  5|  3|803|  6|136|158|211|718|519|  1|368|314|338| 11| 41|373|  3| 94|960|103|248|2084|606|144|223|785|113|233| 32| 14|1483|124|731| 31|450|237| 81| 45| 805|\n",
      "+----------+---+---+---+---+----+---+---+---+---+----+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+----+---+---+---+---+---+---+---+---+----+---+---+---+---+---+---+---+----+\n",
      "\n",
      "+------------------------------+--------+----+-----+---+----+\n",
      "|employment_time_home_ownership|MORTGAGE|NONE|OTHER|OWN|RENT|\n",
      "+------------------------------+--------+----+-----+---+----+\n",
      "|                       5 years|    1153|   1|    3|184|1156|\n",
      "|                       6 years|     828|   0|    2|110| 730|\n",
      "|                       3 years|    1174|   0|    6|184|1698|\n",
      "|                       8 years|     601|   0|    3| 86| 420|\n",
      "|                        1 year|     745|   0|    8|164|1523|\n",
      "|                      < 1 year|     976|   2|   16|264|2188|\n",
      "|                       9 years|     525|   0|    0| 67| 348|\n",
      "|                           n/a|     332|   0|    0|161| 299|\n",
      "|                       4 years|    1075|   0|    6|171|1339|\n",
      "|                     10+ years|    4129|   0|   15|570|1891|\n",
      "|                       7 years|     660|   0|    3|102| 567|\n",
      "|                       2 years|    1090|   0|    7|209|1964|\n",
      "+------------------------------+--------+----+-----+---+----+\n",
      "\n",
      "+----------------------------+---+-----------+------------------+-----------+----------------+-----+--------------+-------+------+----+-----+----------------+--------------+--------+-------+\n",
      "|employment_time_loan_purpose|car|credit_card|debt_consolidation|educational|home_improvement|house|major_purchase|medical|moving|null|other|renewable_energy|small_business|vacation|wedding|\n",
      "+----------------------------+---+-----------+------------------+-----------+----------------+-----+--------------+-------+------+----+-----+----------------+--------------+--------+-------+\n",
      "|                     5 years| 99|        309|              1156|         18|             175|   24|           138|     31|    24|  94|  224|               5|            97|      25|     78|\n",
      "|                     6 years| 68|        207|               774|          9|             122|   12|            91|     22|    24|  81|  138|               6|            69|       9|     38|\n",
      "|                     3 years|113|        368|              1376|         15|             205|   33|           179|     53|    43| 122|  269|               5|           154|      25|    102|\n",
      "|                     8 years| 44|        135|               541|          4|              99|    9|            50|     23|     8|  38|   89|               1|            46|       6|     17|\n",
      "|                      1 year|101|        336|              1039|         36|             104|   26|           143|     39|    46| 101|  261|               6|           130|      10|     62|\n",
      "|                    < 1 year|127|        442|              1505|         54|             155|   25|           204|     56|    97| 135|  366|               3|           161|      23|     93|\n",
      "|                     9 years| 38|        130|               428|          9|              81|    7|            41|      8|    14|  40|   89|               4|            30|      10|     11|\n",
      "|                         n/a| 30|         91|               282|          6|              74|    8|            51|     18|    15|  40|  115|               4|            28|      21|      9|\n",
      "|                     4 years| 88|        331|              1159|         21|             185|   26|           134|     37|    36| 122|  245|               4|           116|      29|     58|\n",
      "|                   10+ years|239|        778|              3054|         28|             633|   58|           319|    140|    51| 252|  635|              16|           243|      79|     80|\n",
      "|                     7 years| 55|        164|               628|          7|              94|   15|            52|     16|     6|  60|  123|               9|            62|      11|     30|\n",
      "|                     2 years|119|        403|              1463|         29|             205|   33|           184|     63|    48| 144|  316|               5|           151|      23|     84|\n",
      "+----------------------------+---+-----------+------------------+-----------+----------------+-----+--------------+-------+------+----+-----+----------------+--------------+--------+-------+\n",
      "\n",
      "+---------------------+---+---+---+---+----+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+----+\n",
      "|employment_time_state| AK| AL| AR| AZ|  CA| CO| CT| DC| DE| FL| GA| HI| IA| ID| IL| IN| KS| KY| LA| MA| MD| ME| MI| MN| MO| MS| MT| NC| NE| NH| NJ| NM| NV| NY| OH| OK| OR| PA| RI| SC| SD| TN| TX| UT| VA| VT| WA| WI| WV| WY|null|\n",
      "+---------------------+---+---+---+---+----+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+----+\n",
      "|              5 years|  2| 24| 12| 60| 409| 39| 46|  4| 12|178| 89| 15|  0|  0|102|  0| 24| 17| 21| 82| 69|  0| 48| 35| 39|  2|  2| 50|  1|  4| 99| 12| 37|240| 61| 16| 27|100| 16| 28|  4|  3|174| 16| 86|  3| 62| 23|  7|  3|  94|\n",
      "|              6 years|  2| 18|  7| 40| 286| 31| 29|  9|  5|127| 52|  8|  2|  0| 65|  0| 10| 13| 16| 57| 38|  0| 27| 25| 24|  0|  3| 29|  0|  6| 81|  8| 27|161| 51| 11| 19| 56|  6| 15|  4|  1| 97| 10| 52|  1| 32| 15| 10|  2|  82|\n",
      "|              3 years| 10| 34|  9| 68| 547| 50| 61| 19|  6|235| 88| 14|  0|  0| 91|  0| 18| 23| 31| 91| 81|  0| 39| 39| 47|  0|  4| 72|  0|  8|140| 13| 36|295| 89| 19| 39|118| 11| 34|  5|  2|213| 19|104|  4| 64| 33| 10|  6| 123|\n",
      "|              8 years|  3| 10| 10| 24| 163| 24| 24|  3|  1| 84| 49|  8|  0|  0| 43|  2|  9|  8|  9| 28| 27|  0| 31| 18| 16|  1|  4| 26|  0|  3| 54|  5| 13|106| 40|  6| 12| 38|  5| 11|  1|  0| 70|  4| 35|  2| 23| 13|  4|  2|  38|\n",
      "|               1 year|  0| 28| 10| 53| 425| 65| 45| 22|  2|180| 89|  8|  1|  0| 85|  0| 12| 18| 20| 81| 61|  0| 34| 38| 34|  0|  2| 39|  1| 13| 95|  8| 19|205| 74| 13| 24| 99| 12| 31|  3|  1|179| 16| 92|  1| 52| 33|  7|  8| 102|\n",
      "|             < 1 year|  6| 26|  9| 83| 626| 93| 50| 38|  7|207|116| 13|  0|  2|125|  1| 18| 26| 37|124| 95|  1| 65| 57| 53|  1|  7| 59|  0| 14|141| 12| 34|342|100| 22| 38|114| 12| 38|  6|  3|238| 19|109|  4| 68| 37| 10|  3| 137|\n",
      "|              9 years|  1|  9|  7| 18| 171|  9| 19|  6|  3| 72| 34|  5|  0|  0| 34|  0|  4|  9| 11| 33| 23|  0| 17| 10| 22|  0|  1| 24|  0|  4| 48|  1| 10| 84| 27|  9|  4| 31|  6| 11|  2|  0| 56|  3| 24|  2| 24| 10|  1|  1|  40|\n",
      "|                  n/a|  1| 12|  8| 32| 112| 16| 14|  0|  2| 71| 31|  2|  0|  0| 25|  0|  9|  3|  8| 18| 12|  0| 27| 16| 16|  0|  5| 20|  0|  5| 18|  5| 12| 79| 27|  4|  9| 23|  2|  7|  0|  0| 41|  2| 20|  0| 22|  7|  6|  3|  40|\n",
      "|              4 years|  5| 20| 11| 47| 486| 51| 41|  6|  7|191| 84|  9|  1|  1|114|  1| 15| 13| 31| 83| 56|  0| 34| 42| 40|  0|  7| 42|  0| 10|141| 15| 24|239| 65| 14| 28| 85|  8| 35|  1|  0|169| 17| 83|  4| 53| 27|  8|  5| 122|\n",
      "|            10+ years| 15| 90| 52|117|1053|102|150| 14| 18|465|231| 26|  0|  0|233|  0| 45| 83| 74|185|175|  0|139| 91|124|  3| 14|125|  1| 35|289| 46| 88|605|210| 54| 64|248| 52| 78| 11|  1|431| 39|203| 13|107| 90| 42| 18| 256|\n",
      "|              7 years|  2|  9| 15| 29| 243| 33| 21|  6|  6| 82| 40|  8|  0|  0| 55|  0| 10|  8|  9| 51| 30|  0| 23| 19| 19|  0|  2| 25|  0|  6| 64|  3| 17|114| 42|  9| 11| 48|  5| 12|  2|  1| 82|  5| 56|  2| 19| 18|  9|  2|  60|\n",
      "|              2 years|  4| 41| 22| 80| 553| 66| 50| 25|  6|213|115|  9|  1|  0|115|  2| 18| 18| 27|115| 75|  0| 51| 45| 39|  4| 11| 56|  0| 18|158| 17| 39|303| 82| 25| 32|124| 14| 41|  4|  2|227| 22|134|  5| 69| 31| 11|  6| 145|\n",
      "+---------------------+---+---+---+---+----+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+----+\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------+---+-----------+------------------+-----------+----------------+-----+--------------+-------+------+----+-----+----------------+--------------+--------+-------+\n",
      "|home_ownership_loan_purpose|car|credit_card|debt_consolidation|educational|home_improvement|house|major_purchase|medical|moving|null|other|renewable_energy|small_business|vacation|wedding|\n",
      "+---------------------------+---+-----------+------------------+-----------+----------------+-----+--------------+-------+------+----+-----+----------------+--------------+--------+-------+\n",
      "|                      OTHER|  1|          9|                29|          2|               3|    1|             6|      2|     0|   3|    8|               0|             5|       0|      0|\n",
      "|                        OWN|115|        214|               960|         17|             240|   22|           162|     47|    17|  78|  265|               2|            74|      20|     39|\n",
      "|                   MORTGAGE|558|       1632|              5595|         62|            1699|  106|           669|    222|    79| 544| 1096|              44|           665|     107|    210|\n",
      "|                       RENT|447|       1839|              6820|        155|             190|  147|           749|    235|   316| 604| 1499|              22|           543|     144|    413|\n",
      "|                       NONE|  0|          0|                 1|          0|               0|    0|             0|      0|     0|   0|    2|               0|             0|       0|      0|\n",
      "+---------------------------+---+-----------+------------------+-----------+----------------+-----+--------------+-------+------+----+-----+----------------+--------------+--------+-------+\n",
      "\n",
      "+--------------------+---+---+---+---+----+---+---+---+---+----+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+----+---+---+---+---+---+---+---+---+----+---+---+---+---+---+---+---+----+\n",
      "|home_ownership_state| AK| AL| AR| AZ|  CA| CO| CT| DC| DE|  FL| GA| HI| IA| ID| IL| IN| KS| KY| LA| MA| MD| ME| MI| MN| MO| MS| MT| NC| NE| NH| NJ| NM| NV|  NY| OH| OK| OR| PA| RI| SC| SD| TN|  TX| UT| VA| VT| WA| WI| WV| WY|null|\n",
      "+--------------------+---+---+---+---+----+---+---+---+---+----+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+----+---+---+---+---+---+---+---+---+----+---+---+---+---+---+---+---+----+\n",
      "|               OTHER|  0|  0|  0|  2|  13|  4|  0|  3|  0|   4|  3|  0|  0|  0|  2|  0|  2|  0|  0|  4|  2|  0|  2|  0|  1|  0|  1|  0|  0|  0|  1|  0|  1|   6|  2|  0|  1|  1|  1|  0|  0|  0|   5|  0|  3|  2|  0|  0|  0|  0|   3|\n",
      "|                 OWN|  4| 49| 23| 39| 277| 27| 40|  7|  7| 192| 74|  8|  1|  1| 73|  0| 23| 27| 36| 71| 54|  0| 48| 29| 33|  0|  7| 43|  0| 13|123| 14| 16| 251| 66| 18| 10|118|  8| 37|  4|  1| 182|  6| 73|  1| 23| 14| 17|  6|  78|\n",
      "|            MORTGAGE| 27|206|111|368|1635|284|263| 42| 37|1009|626| 36|  2|  2|541|  3|106|155|156|342|352|  0|331|236|289|  6| 32|335|  1| 60|457| 83|190| 658|487|129|119|480| 76|206| 26|  6|1085|109|476| 16|253|177| 80| 34| 548|\n",
      "|                RENT| 20| 66| 38|242|3148|264|247|100| 31| 900|315| 81|  2|  0|471|  3| 61| 57|102|530|334|  1|154|170|150|  5| 22|189|  2| 53|747| 48|149|1858|313| 55|177|485| 64| 98| 13|  7| 705| 57|445| 22|319|146| 28| 19| 610|\n",
      "|                NONE|  0|  0|  0|  0|   1|  0|  0|  0|  0|   0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  1|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|   0|  0|  0|  0|  0|  0|  0|  0|  0|   0|  0|  1|  0|  0|  0|  0|  0|   0|\n",
      "+--------------------+---+---+---+---+----+---+---+---+---+----+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+----+---+---+---+---+---+---+---+---+----+---+---+---+---+---+---+---+----+\n",
      "\n",
      "+------------------+---+---+---+---+----+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+----+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+----+\n",
      "|loan_purpose_state| AK| AL| AR| AZ|  CA| CO| CT| DC| DE| FL| GA| HI| IA| ID| IL| IN| KS| KY| LA| MA| MD| ME| MI| MN| MO| MS| MT| NC| NE| NH| NJ| NM| NV|  NY| OH| OK| OR| PA| RI| SC| SD| TN| TX| UT| VA| VT| WA| WI| WV| WY|null|\n",
      "+------------------+---+---+---+---+----+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+----+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+----+\n",
      "|              null|  0|  0|  0|  0|   0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|   0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|1229|\n",
      "|    major_purchase|  2| 20| 15| 39| 236| 27| 38|  6|  3|128| 53| 12|  0|  0| 63|  0|  9| 22| 28| 52| 48|  0| 38| 18| 28|  0|  5| 21|  0|  1| 79|  8| 23| 136| 43| 17|  4| 83|  7| 25|  1|  2|127|  1| 40|  4| 34| 21| 10|  9|   0|\n",
      "|debt_consolidation| 22|163| 78|273|2475|284|252| 79| 35|936|448| 55|  3|  1|511|  5| 94|117|127|470|347|  0|213|204|227|  3| 21|268|  3| 68|652| 82|153|1348|424| 82|169|479| 77|143| 18|  2|869| 78|496| 19|285|156| 66| 22|   3|\n",
      "|       credit_card|  5| 36| 20| 92| 779| 94| 63| 31|  8|264|104| 10|  0|  0|167|  0| 23| 21| 35|105| 76|  1| 55| 66| 63|  0| 10| 56|  0| 18|157| 14| 53| 343|100| 24| 40|120| 19| 28| 12|  3|263| 28|119|  5| 85| 53| 16|  5|   5|\n",
      "|  home_improvement|  8| 25| 16| 52| 278| 31| 54|  8|  8|188|103| 10|  0|  0| 72|  0| 13| 21| 24| 76| 62|  0| 51| 30| 42|  1|  5| 59|  0|  9| 94| 14| 30| 167| 72| 12| 14|101| 11| 31|  1|  0|167| 12| 83|  3| 40| 24|  6|  4|   0|\n",
      "|  renewable_energy|  0|  1|  0|  3|   9|  3|  3|  0|  0|  6|  0|  0|  0|  0|  2|  0|  1|  1|  2|  1|  2|  0|  5|  3|  2|  0|  0|  2|  0|  1|  1|  0|  1|   5|  0|  0|  1|  2|  0|  0|  0|  0|  7|  1|  3|  0|  0|  0|  0|  0|   0|\n",
      "|    small_business|  6| 14|  6| 36| 218| 27| 23|  3|  2|100| 58|  8|  0|  0| 54|  0|  9| 12| 10| 34| 23|  0| 29| 21| 19|  0|  5| 30|  0|  4| 45|  1| 13| 112| 47| 14| 16| 32|  2| 17|  4|  2|113| 17| 42|  4| 31| 18|  5|  1|   0|\n",
      "|            moving|  0|  3|  0| 12|  77| 11|  6|  4|  1| 34| 16|  3|  0|  0|  8|  0|  3|  3|  1| 14| 12|  0|  8|  5|  5|  1|  3|  7|  0|  1| 32|  1|  1|  54|  9|  3|  5| 14|  3|  5|  0|  0| 26|  0| 12|  1|  5|  3|  0|  0|   0|\n",
      "|               car|  0| 15| 10| 27| 163| 25| 26|  4|  4| 80| 55|  4|  0|  0| 40|  0|  8| 13| 15| 32| 31|  0| 27| 20| 21|  1|  2| 25|  0|  4| 42| 11| 20|  89| 37|  6| 12| 59|  4| 19|  1|  1| 67|  7| 44|  0| 21| 18|  7|  4|   0|\n",
      "|          vacation|  1|  1|  2|  3|  61|  3|  6|  4|  0| 19|  8|  2|  0|  0|  4|  0|  1|  3|  4| 10| 13|  0|  2|  3|  4|  0|  0|  4|  0|  1| 15|  0|  5|  31|  6|  3|  2|  9|  1|  1|  0|  0| 13|  3|  8|  0|  8|  4|  3|  0|   0|\n",
      "|       educational|  0|  3|  2|  5|  27|  8|  2|  0|  0| 24| 10|  3|  0|  0| 11|  0|  2|  1|  1|  9|  7|  0|  9|  3|  4|  2|  1|  1|  0|  1| 12|  1|  1|  27| 11|  3|  3|  9|  2|  5|  0|  1|  9|  4|  5|  0|  5|  2|  0|  0|   0|\n",
      "|             house|  0|  3|  0|  8|  49|  9|  5|  1|  0| 31|  9|  0|  0|  0|  9|  0|  2|  2|  6| 10|  6|  0| 12|  4|  4|  0|  0|  7|  0|  1|  8|  2|  5|  19| 10|  1|  5|  8|  1|  0|  0|  0| 15|  1| 11|  0|  5|  6|  0|  1|   0|\n",
      "|           medical|  0|  5|  5| 15|  90| 15|  7|  0|  1| 39| 28|  1|  1|  0| 18|  0|  3|  2| 10| 11| 10|  0| 11| 11|  7|  0|  3| 12|  0|  2| 19|  2|  8|  45| 17|  8|  5| 12|  1|  7|  0|  0| 36|  7| 16|  0|  9|  2|  3|  2|   0|\n",
      "|           wedding|  0|  3|  1| 14| 121|  6| 11|  5|  3| 45| 22|  3|  0|  0| 32|  0|  3|  1|  7| 29| 22|  0| 12|  5|  7|  2|  1| 15|  0|  1| 41|  1|  7|  88| 18|  0|  3| 33|  3|  9|  1|  0| 46|  0| 25|  0| 10|  4|  0|  1|   1|\n",
      "|             other|  7| 29| 17| 72| 491| 36| 54|  7| 10|211|104| 14|  1|  2| 96|  1| 21| 20| 24| 95| 83|  0| 63| 42| 40|  1|  6| 60|  0| 14|131|  8| 36| 309| 74| 29| 28|123| 18| 51|  5|  3|219| 13| 94|  5| 57| 26|  9| 10|   1|\n",
      "+------------------+---+---+---+---+----+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+----+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# cross tables distribution\n",
    "loanDF.stat.crosstab('term','employment_time').show()\n",
    "loanDF.stat.crosstab('term','home_ownership').show()\n",
    "loanDF.stat.crosstab('term','loan_purpose').show()\n",
    "loanDF.stat.crosstab('term','state').show()\n",
    "loanDF.stat.crosstab('employment_time','home_ownership').show()\n",
    "loanDF.stat.crosstab('employment_time','loan_purpose').show()\n",
    "loanDF.stat.crosstab('employment_time','state').show()\n",
    "loanDF.stat.crosstab('home_ownership','loan_purpose').show()\n",
    "loanDF.stat.crosstab('home_ownership','state').show()\n",
    "loanDF.stat.crosstab('loan_purpose','state').show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Covariance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Covariance of loan_amount and loan_amount\n",
      "55229613.06533747\n",
      "\n",
      "Covariance of loan_amount and interest_rate\n",
      "8549.319317863159\n",
      "\n",
      "Covariance of loan_amount and monthly_payment\n",
      "1436013.2198559118\n",
      "\n",
      "Covariance of loan_amount and annual_income\n",
      "128790952.5486099\n",
      "\n",
      "Covariance of loan_amount and deliquency_past_2years\n",
      "-111.91643190399427\n",
      "\n",
      "Covariance of loan_amount and total_payment\n",
      "56278750.18753406\n",
      "\n",
      "Covariance of loan_amount and revolving_balance\n",
      "35052983.98744884\n",
      "\n",
      "Covariance of loan_amount and revolving_utilization_rate\n",
      "205.5056356256766\n",
      "\n",
      "Covariance of interest_rate and loan_amount\n",
      "8549.31931786316\n",
      "\n",
      "Covariance of interest_rate and interest_rate\n",
      "13.824694456679978\n",
      "\n",
      "Covariance of interest_rate and monthly_payment\n",
      "220.26613109833838\n",
      "\n",
      "Covariance of interest_rate and annual_income\n",
      "12508.30669074606\n",
      "\n",
      "Covariance of interest_rate and deliquency_past_2years\n",
      "0.27668654772190204\n",
      "\n",
      "Covariance of interest_rate and total_payment\n",
      "9885.688703886828\n",
      "\n",
      "Covariance of interest_rate and revolving_balance\n",
      "5542.169383168114\n",
      "\n",
      "Covariance of interest_rate and revolving_utilization_rate\n",
      "0.7111543706734388\n",
      "\n",
      "Covariance of monthly_payment and loan_amount\n",
      "1436013.2198559118\n",
      "\n",
      "Covariance of monthly_payment and interest_rate\n",
      "220.26613109833843\n",
      "\n",
      "Covariance of monthly_payment and monthly_payment\n",
      "43195.378666464145\n",
      "\n",
      "Covariance of monthly_payment and annual_income\n",
      "3575839.640703561\n",
      "\n",
      "Covariance of monthly_payment and deliquency_past_2years\n",
      "-1.8363588466821552\n",
      "\n",
      "Covariance of monthly_payment and total_payment\n",
      "1522445.9444400186\n",
      "\n",
      "Covariance of monthly_payment and revolving_balance\n",
      "968689.8265118104\n",
      "\n",
      "Covariance of monthly_payment and revolving_utilization_rate\n",
      "8.651465419566007\n",
      "\n",
      "Covariance of annual_income and loan_amount\n",
      "128790952.54860988\n",
      "\n",
      "Covariance of annual_income and interest_rate\n",
      "12508.306690746062\n",
      "\n",
      "Covariance of annual_income and monthly_payment\n",
      "3575839.640703561\n",
      "\n",
      "Covariance of annual_income and annual_income\n",
      "4446654604.173155\n",
      "\n",
      "Covariance of annual_income and deliquency_past_2years\n",
      "731.7058910213528\n",
      "\n",
      "Covariance of annual_income and total_payment\n",
      "141110392.6789508\n",
      "\n",
      "Covariance of annual_income and revolving_balance\n",
      "266540251.10995787\n",
      "\n",
      "Covariance of annual_income and revolving_utilization_rate\n",
      "486.9741653775165\n",
      "\n",
      "Covariance of deliquency_past_2years and loan_amount\n",
      "-111.91643190399427\n",
      "\n",
      "Covariance of deliquency_past_2years and interest_rate\n",
      "0.2766865477219021\n",
      "\n",
      "Covariance of deliquency_past_2years and monthly_payment\n",
      "-1.8363588466821554\n",
      "\n",
      "Covariance of deliquency_past_2years and annual_income\n",
      "731.7058910213534\n",
      "\n",
      "Covariance of deliquency_past_2years and deliquency_past_2years\n",
      "0.22692201182729227\n",
      "\n",
      "Covariance of deliquency_past_2years and total_payment\n",
      "-13.44029343493197\n",
      "\n",
      "Covariance of deliquency_past_2years and revolving_balance\n",
      "-334.5073642110974\n",
      "\n",
      "Covariance of deliquency_past_2years and revolving_utilization_rate\n",
      "-0.004945012215610791\n",
      "\n",
      "Covariance of total_payment and loan_amount\n",
      "56278750.18753406\n",
      "\n",
      "Covariance of total_payment and interest_rate\n",
      "9885.688703886832\n",
      "\n",
      "Covariance of total_payment and monthly_payment\n",
      "1522445.9444400186\n",
      "\n",
      "Covariance of total_payment and annual_income\n",
      "141110392.6789508\n",
      "\n",
      "Covariance of total_payment and deliquency_past_2years\n",
      "-13.440293434931977\n",
      "\n",
      "Covariance of total_payment and total_payment\n",
      "84988035.99104434\n",
      "\n",
      "Covariance of total_payment and revolving_balance\n",
      "46924919.06026081\n",
      "\n",
      "Covariance of total_payment and revolving_utilization_rate\n",
      "583.3031384397749\n",
      "\n",
      "Covariance of revolving_balance and loan_amount\n",
      "35052983.98744884\n",
      "\n",
      "Covariance of revolving_balance and interest_rate\n",
      "5542.169383168116\n",
      "\n",
      "Covariance of revolving_balance and monthly_payment\n",
      "968689.8265118101\n",
      "\n",
      "Covariance of revolving_balance and annual_income\n",
      "266540251.10995787\n",
      "\n",
      "Covariance of revolving_balance and deliquency_past_2years\n",
      "-334.5073642110973\n",
      "\n",
      "Covariance of revolving_balance and total_payment\n",
      "46924919.060260795\n",
      "\n",
      "Covariance of revolving_balance and revolving_balance\n",
      "250874730.56832606\n",
      "\n",
      "Covariance of revolving_balance and revolving_utilization_rate\n",
      "2169.436782310638\n",
      "\n",
      "Covariance of revolving_utilization_rate and loan_amount\n",
      "205.50563562567672\n",
      "\n",
      "Covariance of revolving_utilization_rate and interest_rate\n",
      "0.7111543706734388\n",
      "\n",
      "Covariance of revolving_utilization_rate and monthly_payment\n",
      "8.651465419566003\n",
      "\n",
      "Covariance of revolving_utilization_rate and annual_income\n",
      "486.97416537751644\n",
      "\n",
      "Covariance of revolving_utilization_rate and deliquency_past_2years\n",
      "-0.004945012215610791\n",
      "\n",
      "Covariance of revolving_utilization_rate and total_payment\n",
      "583.3031384397748\n",
      "\n",
      "Covariance of revolving_utilization_rate and revolving_balance\n",
      "2169.436782310638\n",
      "\n",
      "Covariance of revolving_utilization_rate and revolving_utilization_rate\n",
      "0.24921992783551733\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# covariance\n",
    "for i in numeric_df:\n",
    "    for j in numeric_df:\n",
    "        print('Covariance of ' + i + ' and '+ j )\n",
    "        print(loanDF.stat.cov(i, j))\n",
    "        print(\"\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ETL summary |  Spark code for Imputing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we present the steps we decided to follow during our EDA in order to prepare our dataset for our machine learning implementation. It is worth mentioning that some of the steps had to be included in the previous part of the assignment in order to have a complete overview of the *cross table distributions* and the *covariances*.\n",
    "\n",
    "1. **interest_rate** : remove special % character and change datatype from *string* to *decimal*.\n",
    "2. **revol_util** : change datatype from *string* to *decimal*.\n",
    "3. **Rename** columns to be better represented.\n",
    "4. **Trim** the variable title as there are multiple unnecessary dots.\n",
    "5. **Checkin for Na**: \n",
    "    1. Number of rows with NA for *loanDF*:    29755\n",
    "    2. Number of rows without NA for *loanDF*: 27773\n",
    "    3. Number of rows with NA for *testDF*:    10024\n",
    "    4. Number of rows without NA for *testDF*: 9116\n",
    "6. **Filling Na values**:\n",
    "    1. **title** :                      unknown\n",
    "    2. **loan_purpose** :               unknown\n",
    "    3. **state** :                      unknown\n",
    "    4. **deliquency_past_2years** :     -1\n",
    "    5. **revolving_balance** :          13350.529071398512 (avg)\n",
    "    6. **revolving_utilization_rate** : 0.5054 (avg)\n",
    "    7. **total_payment** :              12143.791490200982 (avg)\n",
    "7. **Drop** variables *title* and *state* cause they have too many unique values that cannot be grouped in order to apply one hot coding.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Imputing Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29755\n",
      "10024\n"
     ]
    }
   ],
   "source": [
    "loanDF = loanDF.na.fill({'title': 'uknown', 'loan_purpose': 'unknown', 'state': 'unknown',\n",
    "                         'deliquency_past_2years':-1,'revolving_balance':13350.529071398512,\n",
    "                         'revolving_utilization_rate':0.5054 , 'total_payment': 12143.791490200982})\n",
    "\n",
    "testDF = testDF.na.fill({'title': 'unknown', 'loan_purpose': 'uknown', 'state': 'unknown',\n",
    "                         'deliquency_past_2years':-1,'revolving_balance':13350.529071398512,\n",
    "                         'revolving_utilization_rate':0.5054 , 'total_payment': 12143.791490200982})\n",
    "print(loanDF.count())\n",
    "print(testDF.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# assembler_scale = VectorAssembler().setInputCols(numeric_df).setOutputCol('scaled_features')\n",
    "# transformed = assembler_scale.transform(loanDF)\n",
    "# scaler_loan_amount = MinMaxScaler(inputCol=\"loan_amount\", outputCol=\"scaled_loan_amount\")\n",
    "# scalerModel_loan_amount = scaler_loan_amount.fit(transformed.select('scaled_features'))\n",
    "# # scalerModel_loan_amount = scaler_loan_amount.fit(testDF)\n",
    "\n",
    "# scaledData= scalerModel_loan_amount.transform(transformed)\n",
    "# # testDF = scalerModel_loan_amount.transform(testDF)\n",
    "\n",
    "# # #############################################################################################################\n",
    "# # scaler_interest_rate = MinMaxScaler(inputCol=\"interest_rate\", outputCol=\"scaled_interest_rate\")\n",
    "# # scalerModel_interest_rate = scaler_interest_rate.fit(loanDF)\n",
    "# # scalerModel_interest_rate = scaler_interest_rate.fit(testDF)\n",
    "\n",
    "# # scaledData_interest_rate = scalerModel_interest_rate.transform(loanDF)\n",
    "# # scaledData_interest_rate = scalerModel_interest_rate.transform(testDF)\n",
    "\n",
    "# # #############################################################################################################\n",
    "# # scaler_annual_income = MinMaxScaler(inputCol=\"annual_income\", outputCol=\"scaled_annual_income\")\n",
    "# # scalerModel_annual_income = scaler_annual_income.fit(loanDF)\n",
    "# # scalerModel_annual_income = scaler_annual_income.fit(testDF)\n",
    "\n",
    "# # scaledData_annual_income = scalerModel_annual_income.transform(loanDF)\n",
    "# # scaledData_annual_income = scalerModel_annual_income.transform(testDF)\n",
    "\n",
    "# # #############################################################################################################\n",
    "# # scaler_revolving_balance = MinMaxScaler(inputCol=\"revolving_balance\", outputCol=\"scaled_revolving_balance\")\n",
    "# # scalerModel_revolving_balance = scaler_revolving_balance.fit(loanDF)\n",
    "# # scalerModel_revolving_balance = scaler_revolving_balance.fit(testDF)\n",
    "\n",
    "# # scaledData_revolving_balance = scalerModel_revolving_balance.transform(loanDF)\n",
    "# # scaledData_revolving_balance = scalerModel_revolving_balance.transform(testDF)\n",
    "\n",
    "# # #############################################################################################################\n",
    "# # scaler_total_payment = MinMaxScaler(inputCol=\"total_payment\", outputCol=\"scaled_total_payment\")\n",
    "# # scalerModel_total_payment = scaler_total_payment.fit(loanDF)\n",
    "# # scalerModel_total_payment = scaler_total_payment.fit(testDF)\n",
    "\n",
    "# # scaledData_total_payment = scalerModel_total_payment.transform(loanDF)\n",
    "# # scaledData_total_payment = scalerModel_total_payment.transform(testDF)\n",
    "\n",
    "# # #############################################################################################################\n",
    "\n",
    "# # print(loanDF.count())\n",
    "# # print(testDF.count())\n",
    "\n",
    "# loanDF.describe('loan_amount').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Double checking final clean dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking all our columns to verify that we have:\n",
    "   * Distinct user id so we do not need to group by.\n",
    "   * Clean data format.\n",
    "   * Clean cell values, (for example no Na and nan, which mean the same thing) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+----------+------------------+-----+---------------+--------------+\n",
      "|summary|       loan_amount|      term|     interest_rate|title|employment_time|home_ownership|\n",
      "+-------+------------------+----------+------------------+-----+---------------+--------------+\n",
      "|  count|             29755|     29755|             29755|29755|          29755|         29755|\n",
      "|   mean|11218.509494202655|      null|           12.0301| null|           null|          null|\n",
      "| stddev| 7431.662873498601|      null|3.7181574007403158| null|           null|          null|\n",
      "|    min|               500| 36 months|                 5|     |         1 year|      MORTGAGE|\n",
      "|    max|             35000| 60 months|                25|    ",
      "|            n/a|          RENT|\n",
      "+-------+------------------+----------+------------------+-----+---------------+--------------+\n",
      "\n",
      "+-------+----------------+------------+------------------+-------+----------------------+\n",
      "|summary|   annual_income|loan_purpose|   monthly_payment|  state|deliquency_past_2years|\n",
      "+-------+----------------+------------+------------------+-------+----------------------+\n",
      "|  count|           29755|       29755|             29755|  29755|                 29755|\n",
      "|   mean|69044.8235268022|        null|324.23834481599505|   null|   0.09823559065703243|\n",
      "| stddev|66683.2408043667|        null|207.83497941026226|   null|    0.5277108787429355|\n",
      "|    min|          4000.0|         car|             15.69|     AK|                    -1|\n",
      "|    max|       6000000.0|     wedding|           1305.19|unknown|                     8|\n",
      "+-------+----------------+------------+------------------+-------+----------------------+\n",
      "\n",
      "+-------+------------------+--------------------------+------------------+-------------------+\n",
      "|summary| revolving_balance|revolving_utilization_rate|     total_payment|        loan_status|\n",
      "+-------+------------------+--------------------------+------------------+-------------------+\n",
      "|  count|             29755|                     29755|             29755|              29755|\n",
      "|   mean|13350.507040833474|                    0.5382|12143.791490200865|0.14199294236262813|\n",
      "| stddev|15612.871329442776|       0.49854478904257155| 8893.976006787383| 0.3490487663481529|\n",
      "|    min|                 0|                         0|               0.0|                  0|\n",
      "|    max|            149588|                         1|       58886.47343|                  1|\n",
      "+-------+------------------+--------------------------+------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loanDF.describe('loan_amount','term','interest_rate','title','employment_time','home_ownership').show()\n",
    "loanDF.describe('annual_income','loan_purpose','monthly_payment','state','deliquency_past_2years').show()\n",
    "loanDF.describe('revolving_balance','revolving_utilization_rate','total_payment','loan_status').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29755\n",
      "+----+\n",
      "|  id|\n",
      "+----+\n",
      "| 496|\n",
      "| 833|\n",
      "|1088|\n",
      "|1238|\n",
      "|1342|\n",
      "|1580|\n",
      "|1645|\n",
      "|1829|\n",
      "|1959|\n",
      "|2122|\n",
      "|2366|\n",
      "|2866|\n",
      "|3749|\n",
      "|3918|\n",
      "|4101|\n",
      "|4519|\n",
      "|4818|\n",
      "|4900|\n",
      "|4935|\n",
      "|5156|\n",
      "+----+\n",
      "only showing top 20 rows\n",
      "\n",
      "None\n",
      "824\n",
      "+-----------+\n",
      "|loan_amount|\n",
      "+-----------+\n",
      "|       5300|\n",
      "|      18800|\n",
      "|       3175|\n",
      "|       4900|\n",
      "|       9900|\n",
      "|      21700|\n",
      "|      11500|\n",
      "|      16500|\n",
      "|      19200|\n",
      "|      14075|\n",
      "|       3475|\n",
      "|       3000|\n",
      "|       7850|\n",
      "|      11800|\n",
      "|       6825|\n",
      "|      11025|\n",
      "|       1650|\n",
      "|      26375|\n",
      "|      15575|\n",
      "|       8650|\n",
      "+-----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "None\n",
      "2\n",
      "+----------+\n",
      "|      term|\n",
      "+----------+\n",
      "| 36 months|\n",
      "| 60 months|\n",
      "+----------+\n",
      "\n",
      "None\n",
      "21\n",
      "+-------------+\n",
      "|interest_rate|\n",
      "+-------------+\n",
      "|           19|\n",
      "|           22|\n",
      "|            7|\n",
      "|           25|\n",
      "|            6|\n",
      "|            9|\n",
      "|           17|\n",
      "|            5|\n",
      "|           10|\n",
      "|           12|\n",
      "|            8|\n",
      "|           11|\n",
      "|           13|\n",
      "|           18|\n",
      "|           14|\n",
      "|           21|\n",
      "|           15|\n",
      "|           23|\n",
      "|           20|\n",
      "|           16|\n",
      "+-------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "None\n",
      "12919\n",
      "+---------------+\n",
      "|monthly_payment|\n",
      "+---------------+\n",
      "|         155.72|\n",
      "|         175.69|\n",
      "|         176.51|\n",
      "|         336.66|\n",
      "|         524.96|\n",
      "|         636.09|\n",
      "|         539.14|\n",
      "|          206.4|\n",
      "|          834.5|\n",
      "|         718.29|\n",
      "|         302.17|\n",
      "|         149.34|\n",
      "|         179.66|\n",
      "|         606.41|\n",
      "|          77.19|\n",
      "|         524.55|\n",
      "|         462.97|\n",
      "|          194.7|\n",
      "|         528.73|\n",
      "|         361.12|\n",
      "+---------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "None\n",
      "12\n",
      "+---------------+\n",
      "|employment_time|\n",
      "+---------------+\n",
      "|        9 years|\n",
      "|        5 years|\n",
      "|         1 year|\n",
      "|            n/a|\n",
      "|        2 years|\n",
      "|        7 years|\n",
      "|        8 years|\n",
      "|        4 years|\n",
      "|        6 years|\n",
      "|        3 years|\n",
      "|      10+ years|\n",
      "|       < 1 year|\n",
      "+---------------+\n",
      "\n",
      "None\n",
      "5\n",
      "+--------------+\n",
      "|home_ownership|\n",
      "+--------------+\n",
      "|           OWN|\n",
      "|          RENT|\n",
      "|      MORTGAGE|\n",
      "|         OTHER|\n",
      "|          NONE|\n",
      "+--------------+\n",
      "\n",
      "None\n",
      "4308\n",
      "+-------------+\n",
      "|annual_income|\n",
      "+-------------+\n",
      "|     300000.0|\n",
      "|      51300.0|\n",
      "|      74999.0|\n",
      "|     147000.0|\n",
      "|      62742.0|\n",
      "|     209004.0|\n",
      "|      86095.0|\n",
      "|     26989.22|\n",
      "|      87240.0|\n",
      "|      27552.0|\n",
      "|     330000.0|\n",
      "|     137720.0|\n",
      "|       4800.0|\n",
      "|      59484.0|\n",
      "|      54050.0|\n",
      "|     46809.24|\n",
      "|     102058.0|\n",
      "|      58327.0|\n",
      "|      53004.0|\n",
      "|      56400.0|\n",
      "+-------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "None\n",
      "15\n",
      "+------------------+\n",
      "|      loan_purpose|\n",
      "+------------------+\n",
      "|           unknown|\n",
      "|           wedding|\n",
      "|       educational|\n",
      "|             other|\n",
      "|    small_business|\n",
      "|debt_consolidation|\n",
      "|       credit_card|\n",
      "|            moving|\n",
      "|          vacation|\n",
      "|  renewable_energy|\n",
      "|             house|\n",
      "|               car|\n",
      "|    major_purchase|\n",
      "|           medical|\n",
      "|  home_improvement|\n",
      "+------------------+\n",
      "\n",
      "None\n",
      "3\n",
      "+------+\n",
      "| title|\n",
      "+------+\n",
      "|     ",
      "|\n",
      "|uknown|\n",
      "|      |\n",
      "+------+\n",
      "\n",
      "None\n",
      "51\n",
      "+-------+\n",
      "|  state|\n",
      "+-------+\n",
      "|     AZ|\n",
      "|     SC|\n",
      "|     LA|\n",
      "|     MN|\n",
      "|     NJ|\n",
      "|     DC|\n",
      "|     OR|\n",
      "|unknown|\n",
      "|     VA|\n",
      "|     RI|\n",
      "|     WY|\n",
      "|     KY|\n",
      "|     NH|\n",
      "|     MI|\n",
      "|     NV|\n",
      "|     WI|\n",
      "|     ID|\n",
      "|     CA|\n",
      "|     CT|\n",
      "|     NE|\n",
      "+-------+\n",
      "only showing top 20 rows\n",
      "\n",
      "None\n",
      "10\n",
      "+----------------------+\n",
      "|deliquency_past_2years|\n",
      "+----------------------+\n",
      "|                    -1|\n",
      "|                     1|\n",
      "|                     6|\n",
      "|                     3|\n",
      "|                     5|\n",
      "|                     4|\n",
      "|                     8|\n",
      "|                     7|\n",
      "|                     2|\n",
      "|                     0|\n",
      "+----------------------+\n",
      "\n",
      "None\n",
      "17737\n",
      "+-----------------+\n",
      "|revolving_balance|\n",
      "+-----------------+\n",
      "|            23336|\n",
      "|             6654|\n",
      "|            30361|\n",
      "|            22373|\n",
      "|             6397|\n",
      "|            13285|\n",
      "|              496|\n",
      "|            11317|\n",
      "|             5300|\n",
      "|             6620|\n",
      "|            35694|\n",
      "|            14570|\n",
      "|             7554|\n",
      "|            14450|\n",
      "|            19553|\n",
      "|            11141|\n",
      "|            10362|\n",
      "|            43527|\n",
      "|            18498|\n",
      "|             7240|\n",
      "+-----------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "None\n",
      "2\n",
      "+--------------------------+\n",
      "|revolving_utilization_rate|\n",
      "+--------------------------+\n",
      "|                         0|\n",
      "|                         1|\n",
      "+--------------------------+\n",
      "\n",
      "None\n",
      "27316\n",
      "+-------------+\n",
      "|total_payment|\n",
      "+-------------+\n",
      "|  7328.920002|\n",
      "|       6199.8|\n",
      "|     11604.88|\n",
      "|      8653.52|\n",
      "|  35112.47436|\n",
      "|  21460.20219|\n",
      "|  17468.40321|\n",
      "|  11876.61543|\n",
      "|  5939.781563|\n",
      "|  15471.33453|\n",
      "|  26567.47779|\n",
      "|   53945.0115|\n",
      "|  24645.63911|\n",
      "|  10196.37663|\n",
      "|  8492.268341|\n",
      "|  9715.619997|\n",
      "|      5507.39|\n",
      "|  29828.39368|\n",
      "|     13014.67|\n",
      "|  12425.89146|\n",
      "+-------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "None\n",
      "2\n",
      "+-----------+\n",
      "|loan_status|\n",
      "+-----------+\n",
      "|          1|\n",
      "|          0|\n",
      "+-----------+\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# we have unique id = number of rows of dataset, so we do not need to group by.\n",
    "for i in loanDF.columns:\n",
    "    print(loanDF.select(i).distinct().count())\n",
    "    print(loanDF.select(i).distinct().show())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this stage we check the final structure of the table and we also decide to drop the **title** and **state** feature as they have so many different values, which makes it difficult to use in our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- loan_amount: integer (nullable = true)\n",
      " |-- term: string (nullable = true)\n",
      " |-- interest_rate: decimal(10,0) (nullable = true)\n",
      " |-- monthly_payment: double (nullable = true)\n",
      " |-- employment_time: string (nullable = true)\n",
      " |-- home_ownership: string (nullable = true)\n",
      " |-- annual_income: double (nullable = true)\n",
      " |-- loan_purpose: string (nullable = false)\n",
      " |-- deliquency_past_2years: integer (nullable = false)\n",
      " |-- revolving_balance: integer (nullable = true)\n",
      " |-- revolving_utilization_rate: decimal(10,0) (nullable = true)\n",
      " |-- total_payment: double (nullable = false)\n",
      " |-- loan_status: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- loan_amount: integer (nullable = true)\n",
      " |-- term: string (nullable = true)\n",
      " |-- interest_rate: decimal(10,0) (nullable = true)\n",
      " |-- monthly_payment: double (nullable = true)\n",
      " |-- employment_time: string (nullable = true)\n",
      " |-- home_ownership: string (nullable = true)\n",
      " |-- annual_income: double (nullable = true)\n",
      " |-- loan_purpose: string (nullable = false)\n",
      " |-- deliquency_past_2years: integer (nullable = false)\n",
      " |-- revolving_balance: integer (nullable = true)\n",
      " |-- revolving_utilization_rate: decimal(10,0) (nullable = true)\n",
      " |-- total_payment: double (nullable = false)\n",
      " |-- loan_status: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loanDF = loanDF.drop(\"title\", 'state','id')\n",
    "testDF = testDF.drop(\"title\", 'state','id')\n",
    "loanDF.printSchema()\n",
    "testDF.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Pipeline | Split train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- loan_amount: integer (nullable = true)\n",
      " |-- term: string (nullable = true)\n",
      " |-- interest_rate: decimal(10,0) (nullable = true)\n",
      " |-- monthly_payment: double (nullable = true)\n",
      " |-- employment_time: string (nullable = true)\n",
      " |-- home_ownership: string (nullable = true)\n",
      " |-- annual_income: double (nullable = true)\n",
      " |-- loan_purpose: string (nullable = false)\n",
      " |-- deliquency_past_2years: integer (nullable = false)\n",
      " |-- revolving_balance: integer (nullable = true)\n",
      " |-- revolving_utilization_rate: decimal(10,0) (nullable = true)\n",
      " |-- total_payment: double (nullable = false)\n",
      " |-- loan_status: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- loan_amount: integer (nullable = true)\n",
      " |-- term: string (nullable = true)\n",
      " |-- interest_rate: decimal(10,0) (nullable = true)\n",
      " |-- monthly_payment: double (nullable = true)\n",
      " |-- employment_time: string (nullable = true)\n",
      " |-- home_ownership: string (nullable = true)\n",
      " |-- annual_income: double (nullable = true)\n",
      " |-- loan_purpose: string (nullable = false)\n",
      " |-- deliquency_past_2years: integer (nullable = false)\n",
      " |-- revolving_balance: integer (nullable = true)\n",
      " |-- revolving_utilization_rate: decimal(10,0) (nullable = true)\n",
      " |-- total_payment: double (nullable = false)\n",
      " |-- loan_status: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loanDF.printSchema()\n",
    "testDF.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this stage we make the following adjustments:\n",
    "\n",
    "1. We keep the **total_amount** column and we discard the **monthly payment**, because of high correlation between the 2. The reason for keeipng the total amount is based more on a business perspective.\n",
    "2. We keep the **interest_rate** column and we discard the **revolving_utilization_rate**, as they are totally correlated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoricalColumns = ['term', 'employment_time', 'home_ownership', 'loan_purpose']\n",
    "stages = []\n",
    "\n",
    "for categoricalCol in categoricalColumns:\n",
    "    stringIndexer = StringIndexer(inputCol = categoricalCol, outputCol = categoricalCol + 'Index')\n",
    "    encoder = OneHotEncoderEstimator(inputCols=[stringIndexer.getOutputCol()], outputCols=[categoricalCol + \"classVec\"])\n",
    "    stages += [stringIndexer, encoder]\n",
    "    \n",
    "label_stringIdx = StringIndexer(inputCol = 'loan_status', outputCol = 'label')\n",
    "\n",
    "stages += [label_stringIdx]\n",
    "\n",
    "numericCols = ['loan_amount', 'interest_rate', 'annual_income', 'deliquency_past_2years', \n",
    "               'revolving_balance','total_payment']\n",
    "assemblerInputs = [c + \"classVec\" for c in categoricalColumns] + numericCols\n",
    "assembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")\n",
    "\n",
    "stages += [assembler]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it is time for use to define the pipeline we are going to use for all the models that are about to be tested including:\n",
    "1. **Logistic Regression**\n",
    "2. **Random Forest**\n",
    "3. **Gradient Tree Boosting**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- features: vector (nullable = true)\n",
      " |-- label: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline(stages = stages)\n",
    "pipelineModel = pipeline.fit(loanDF)\n",
    "loanDF = pipelineModel.transform(loanDF)\n",
    "selectedCols = ['features' , 'label']\n",
    "loanDF = loanDF.select(selectedCols)\n",
    "loanDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>features</th>\n",
       "      <td>(0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...</td>\n",
       "      <td>(1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                          0  \\\n",
       "features  (0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "label                                                     1   \n",
       "\n",
       "                                                          1  \\\n",
       "features  (1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "label                                                     0   \n",
       "\n",
       "                                                          2  \\\n",
       "features  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...   \n",
       "label                                                     0   \n",
       "\n",
       "                                                          3  \\\n",
       "features  (1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "label                                                     0   \n",
       "\n",
       "                                                          4  \n",
       "features  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "label                                                     0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(loanDF.take(5), columns=loanDF.columns).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Count: 20882\n",
      "Test Dataset Count: 8873\n"
     ]
    }
   ],
   "source": [
    "(trainingData, validationData) = loanDF.randomSplit([0.7, 0.3], seed=100)\n",
    "print(\"Training Dataset Count: \" + str(trainingData.count()))\n",
    "print(\"Test Dataset Count: \" + str(validationData.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regresion Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write a function \"metrics\" which has a LogisticRegressionModel.summary as input attribute and produces an output of: \n",
    "1. Area under ROC\n",
    "2. False Positive Rate By Label\n",
    "3. True Positive Rate By Label\n",
    "4. Precision By Label\n",
    "5. Recall By Label\n",
    "6. fMeasure By Label\n",
    "7. Accuracy\n",
    "8. False Positive Rate\n",
    "9. True Positive Rate\n",
    "10. fMeasure\n",
    "11. Precision\n",
    "12. Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(trainingSummary):  \n",
    "    my_formatted_list_FP = [ '%.2f' % elem for elem in trainingSummary.truePositiveRateByLabel]\n",
    "    my_formatted_list_TP = [ '%.2f' % elem for elem in trainingSummary.precisionByLabel]\n",
    "    my_formatted_list_P = [ '%.2f' % elem for elem in trainingSummary.falsePositiveRateByLabel]\n",
    "    my_formatted_list_R = [ '%.2f' % elem for elem in trainingSummary.recallByLabel]\n",
    "    \n",
    "    print(\"AUC: \" + str(\"%.2f\" % trainingSummary.areaUnderROC))\n",
    "    print('')\n",
    "    print(\"False Positive Rate by Label: \" + str(my_formatted_list_FP))\n",
    "    print('')\n",
    "    print(\"True Positive Rate by Label: \" + str(my_formatted_list_P))\n",
    "    print('')\n",
    "    print(\"Precision by Label: \" + str(my_formatted_list_TP))\n",
    "    print('')\n",
    "    print(\"Recall by Label: \" + str(my_formatted_list_R))\n",
    "    print('')\n",
    "    print(\"fMeasure by Label: \" + str(trainingSummary.fMeasureByLabel))\n",
    "    print('')\n",
    "    print(\"Accuracy: \" + str(\"%.2f\" %trainingSummary.accuracy))\n",
    "    print('')\n",
    "    print(\"False Positive Rate: \" + str(\"%.2f\" %trainingSummary.weightedFalsePositiveRate))\n",
    "    print('')\n",
    "    print(\"True Positive Rate: \" + str(\"%.2f\" %trainingSummary.weightedTruePositiveRate)) \n",
    "    print('')\n",
    "    print(\"fMeasure: \" + str(trainingSummary.weightedFMeasure))\n",
    "    print('')\n",
    "    print(\"Precision: \" + str(\"%.2f\" %trainingSummary.weightedPrecision))\n",
    "    print('')\n",
    "    print(\"Recall: \" + str(\"%.2f\" %trainingSummary.weightedRecall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply a Logistic Regresion Base Model and show the metrics by the function above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are using metric: areaUnderROC\n"
     ]
    }
   ],
   "source": [
    "evaluator = BinaryClassificationEvaluator() \\\n",
    "                .setLabelCol(\"label\") \\\n",
    "                .setRawPredictionCol(\"rawPrediction\")\n",
    "\n",
    "print(\"We are using metric: \" + evaluator.getMetricName())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.90\n",
      "\n",
      "False Positive Rate by Label: ['0.99', '0.52']\n",
      "\n",
      "True Positive Rate by Label: ['0.48', '0.01']\n",
      "\n",
      "Precision by Label: ['0.92', '0.88']\n",
      "\n",
      "Recall by Label: ['0.99', '0.52']\n",
      "\n",
      "fMeasure by Label: <bound method LogisticRegressionSummary.fMeasureByLabel of <pyspark.ml.classification.BinaryLogisticRegressionTrainingSummary object at 0x11c6aec18>>\n",
      "\n",
      "Accuracy: 0.92\n",
      "\n",
      "False Positive Rate: 0.42\n",
      "\n",
      "True Positive Rate: 0.92\n",
      "\n",
      "fMeasure: <bound method LogisticRegressionSummary.weightedFMeasure of <pyspark.ml.classification.BinaryLogisticRegressionTrainingSummary object at 0x11c6aec18>>\n",
      "\n",
      "Precision: 0.92\n",
      "\n",
      "Recall: 0.92\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(featuresCol = 'features', labelCol = 'label', maxIter=10)\n",
    "lrModel = lr.fit(trainingData)\n",
    "trainingSummary = lrModel.summary\n",
    "metrics(trainingSummary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+--------------------+\n",
      "|       rawPrediction|prediction|         probability|\n",
      "+--------------------+----------+--------------------+\n",
      "|[1.67531490572297...|       0.0|[0.84228315027341...|\n",
      "|[0.89174508484855...|       0.0|[0.70925016549909...|\n",
      "|[3.12213984377515...|       0.0|[0.95779680987968...|\n",
      "|[1.99896352972117...|       0.0|[0.88068821228925...|\n",
      "|[1.86675170595399...|       0.0|[0.86608197517861...|\n",
      "|[2.03352338506302...|       0.0|[0.88427213176162...|\n",
      "|[2.02128702119117...|       0.0|[0.88301402429537...|\n",
      "|[1.67041077700678...|       0.0|[0.84163058070899...|\n",
      "|[2.80277319756258...|       0.0|[0.94282549862876...|\n",
      "|[1.76208839570405...|       0.0|[0.85347102412012...|\n",
      "+--------------------+----------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions_lr = lrModel.transform(validationData)\n",
    "predictions_lr.select('rawPrediction', 'prediction', 'probability').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Area Under ROC 0.8993\n"
     ]
    }
   ],
   "source": [
    "print('Test Area Under ROC','%.4f' %  evaluator.evaluate(predictions_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We are going to try to improve our model:\n",
    "1. Using a `weight column` in our Logistic Regression Model (Take into account we are working with a unbalanced dataset)\n",
    "2. Define a `ParamGridBuilder` with `regParam`, `elasticNetParam` and `maxIter` at least\n",
    "3. Define an `BinaryClassificationEvaluator`\n",
    "4. Using Cross Validation with a 5-fold `CrossValidator`\n",
    "\n",
    "Questions to answer:\n",
    "1. Have we improved the ROC-AUC?\n",
    "2. Which are the average ROC-AUC measurements in the different cross validation runs?\n",
    "3. Which are the parameters of the best model in the 5 k-fold runs?\n",
    "4. Which are the metrics of the best model (training) in the 5 k-fold runs? (Use the function above)\n",
    "5. Which is the ROC-AUC on validation dataset?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are using metric: areaUnderROC\n"
     ]
    }
   ],
   "source": [
    "evaluator = BinaryClassificationEvaluator() \\\n",
    "                .setLabelCol(\"label\") \\\n",
    "                .setRawPredictionCol(\"rawPrediction\")\n",
    "\n",
    "print(\"We are using metric: \" + evaluator.getMetricName())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By setting the **paramGrid_lr** variable we define the set of different parameters we would like to test in order to tune our algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param Grid: [{Param(parent='LogisticRegression_409084c8f7e4fc0950c0', name='regParam', doc='regularization parameter (>= 0).'): 0.1, Param(parent='LogisticRegression_409084c8f7e4fc0950c0', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.0, Param(parent='LogisticRegression_409084c8f7e4fc0950c0', name='maxIter', doc='max number of iterations (>= 0).'): 1}, {Param(parent='LogisticRegression_409084c8f7e4fc0950c0', name='regParam', doc='regularization parameter (>= 0).'): 0.1, Param(parent='LogisticRegression_409084c8f7e4fc0950c0', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.0, Param(parent='LogisticRegression_409084c8f7e4fc0950c0', name='maxIter', doc='max number of iterations (>= 0).'): 5}, {Param(parent='LogisticRegression_409084c8f7e4fc0950c0', name='regParam', doc='regularization parameter (>= 0).'): 0.1, Param(parent='LogisticRegression_409084c8f7e4fc0950c0', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.0, Param(parent='LogisticRegression_409084c8f7e4fc0950c0', name='maxIter', doc='max number of iterations (>= 0).'): 10}, {Param(parent='LogisticRegression_409084c8f7e4fc0950c0', name='regParam', doc='regularization parameter (>= 0).'): 0.1, Param(parent='LogisticRegression_409084c8f7e4fc0950c0', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5, Param(parent='LogisticRegression_409084c8f7e4fc0950c0', name='maxIter', doc='max number of iterations (>= 0).'): 1}, {Param(parent='LogisticRegression_409084c8f7e4fc0950c0', name='regParam', doc='regularization parameter (>= 0).'): 0.1, Param(parent='LogisticRegression_409084c8f7e4fc0950c0', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5, Param(parent='LogisticRegression_409084c8f7e4fc0950c0', name='maxIter', doc='max number of iterations (>= 0).'): 5}, {Param(parent='LogisticRegression_409084c8f7e4fc0950c0', name='regParam', doc='regularization parameter (>= 0).'): 0.1, Param(parent='LogisticRegression_409084c8f7e4fc0950c0', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5, Param(parent='LogisticRegression_409084c8f7e4fc0950c0', name='maxIter', doc='max number of iterations (>= 0).'): 10}, {Param(parent='LogisticRegression_409084c8f7e4fc0950c0', name='regParam', doc='regularization parameter (>= 0).'): 0.1, Param(parent='LogisticRegression_409084c8f7e4fc0950c0', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 1.0, Param(parent='LogisticRegression_409084c8f7e4fc0950c0', name='maxIter', doc='max number of iterations (>= 0).'): 1}, {Param(parent='LogisticRegression_409084c8f7e4fc0950c0', name='regParam', doc='regularization parameter (>= 0).'): 0.1, Param(parent='LogisticRegression_409084c8f7e4fc0950c0', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 1.0, Param(parent='LogisticRegression_409084c8f7e4fc0950c0', name='maxIter', doc='max number of iterations (>= 0).'): 5}, {Param(parent='LogisticRegression_409084c8f7e4fc0950c0', name='regParam', doc='regularization parameter (>= 0).'): 0.1, Param(parent='LogisticRegression_409084c8f7e4fc0950c0', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 1.0, Param(parent='LogisticRegression_409084c8f7e4fc0950c0', name='maxIter', doc='max number of iterations (>= 0).'): 10}, {Param(parent='LogisticRegression_409084c8f7e4fc0950c0', name='regParam', doc='regularization parameter (>= 0).'): 0.5, Param(parent='LogisticRegression_409084c8f7e4fc0950c0', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.0, Param(parent='LogisticRegression_409084c8f7e4fc0950c0', name='maxIter', doc='max number of iterations (>= 0).'): 1}, {Param(parent='LogisticRegression_409084c8f7e4fc0950c0', name='regParam', doc='regularization parameter (>= 0).'): 0.5, Param(parent='LogisticRegression_409084c8f7e4fc0950c0', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.0, Param(parent='LogisticRegression_409084c8f7e4fc0950c0', name='maxIter', doc='max number of iterations (>= 0).'): 5}, {Param(parent='LogisticRegression_409084c8f7e4fc0950c0', name='regParam', doc='regularization parameter (>= 0).'): 0.5, Param(parent='LogisticRegression_409084c8f7e4fc0950c0', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.0, Param(parent='LogisticRegression_409084c8f7e4fc0950c0', name='maxIter', doc='max number of iterations (>= 0).'): 10}, {Param(parent='LogisticRegression_409084c8f7e4fc0950c0', name='regParam', doc='regularization parameter (>= 0).'): 0.5, Param(parent='LogisticRegression_409084c8f7e4fc0950c0', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5, Param(parent='LogisticRegression_409084c8f7e4fc0950c0', name='maxIter', doc='max number of iterations (>= 0).'): 1}, {Param(parent='LogisticRegression_409084c8f7e4fc0950c0', name='regParam', doc='regularization parameter (>= 0).'): 0.5, Param(parent='LogisticRegression_409084c8f7e4fc0950c0', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5, Param(parent='LogisticRegression_409084c8f7e4fc0950c0', name='maxIter', doc='max number of iterations (>= 0).'): 5}, {Param(parent='LogisticRegression_409084c8f7e4fc0950c0', name='regParam', doc='regularization parameter (>= 0).'): 0.5, Param(parent='LogisticRegression_409084c8f7e4fc0950c0', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5, Param(parent='LogisticRegression_409084c8f7e4fc0950c0', name='maxIter', doc='max number of iterations (>= 0).'): 10}, {Param(parent='LogisticRegression_409084c8f7e4fc0950c0', name='regParam', doc='regularization parameter (>= 0).'): 0.5, Param(parent='LogisticRegression_409084c8f7e4fc0950c0', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 1.0, Param(parent='LogisticRegression_409084c8f7e4fc0950c0', name='maxIter', doc='max number of iterations (>= 0).'): 1}, {Param(parent='LogisticRegression_409084c8f7e4fc0950c0', name='regParam', doc='regularization parameter (>= 0).'): 0.5, Param(parent='LogisticRegression_409084c8f7e4fc0950c0', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 1.0, Param(parent='LogisticRegression_409084c8f7e4fc0950c0', name='maxIter', doc='max number of iterations (>= 0).'): 5}, {Param(parent='LogisticRegression_409084c8f7e4fc0950c0', name='regParam', doc='regularization parameter (>= 0).'): 0.5, Param(parent='LogisticRegression_409084c8f7e4fc0950c0', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 1.0, Param(parent='LogisticRegression_409084c8f7e4fc0950c0', name='maxIter', doc='max number of iterations (>= 0).'): 10}, {Param(parent='LogisticRegression_409084c8f7e4fc0950c0', name='regParam', doc='regularization parameter (>= 0).'): 2.0, Param(parent='LogisticRegression_409084c8f7e4fc0950c0', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.0, Param(parent='LogisticRegression_409084c8f7e4fc0950c0', name='maxIter', doc='max number of iterations (>= 0).'): 1}, {Param(parent='LogisticRegression_409084c8f7e4fc0950c0', name='regParam', doc='regularization parameter (>= 0).'): 2.0, Param(parent='LogisticRegression_409084c8f7e4fc0950c0', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.0, Param(parent='LogisticRegression_409084c8f7e4fc0950c0', name='maxIter', doc='max number of iterations (>= 0).'): 5}, {Param(parent='LogisticRegression_409084c8f7e4fc0950c0', name='regParam', doc='regularization parameter (>= 0).'): 2.0, Param(parent='LogisticRegression_409084c8f7e4fc0950c0', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.0, Param(parent='LogisticRegression_409084c8f7e4fc0950c0', name='maxIter', doc='max number of iterations (>= 0).'): 10}, {Param(parent='LogisticRegression_409084c8f7e4fc0950c0', name='regParam', doc='regularization parameter (>= 0).'): 2.0, Param(parent='LogisticRegression_409084c8f7e4fc0950c0', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5, Param(parent='LogisticRegression_409084c8f7e4fc0950c0', name='maxIter', doc='max number of iterations (>= 0).'): 1}, {Param(parent='LogisticRegression_409084c8f7e4fc0950c0', name='regParam', doc='regularization parameter (>= 0).'): 2.0, Param(parent='LogisticRegression_409084c8f7e4fc0950c0', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5, Param(parent='LogisticRegression_409084c8f7e4fc0950c0', name='maxIter', doc='max number of iterations (>= 0).'): 5}, {Param(parent='LogisticRegression_409084c8f7e4fc0950c0', name='regParam', doc='regularization parameter (>= 0).'): 2.0, Param(parent='LogisticRegression_409084c8f7e4fc0950c0', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5, Param(parent='LogisticRegression_409084c8f7e4fc0950c0', name='maxIter', doc='max number of iterations (>= 0).'): 10}, {Param(parent='LogisticRegression_409084c8f7e4fc0950c0', name='regParam', doc='regularization parameter (>= 0).'): 2.0, Param(parent='LogisticRegression_409084c8f7e4fc0950c0', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 1.0, Param(parent='LogisticRegression_409084c8f7e4fc0950c0', name='maxIter', doc='max number of iterations (>= 0).'): 1}, {Param(parent='LogisticRegression_409084c8f7e4fc0950c0', name='regParam', doc='regularization parameter (>= 0).'): 2.0, Param(parent='LogisticRegression_409084c8f7e4fc0950c0', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 1.0, Param(parent='LogisticRegression_409084c8f7e4fc0950c0', name='maxIter', doc='max number of iterations (>= 0).'): 5}, {Param(parent='LogisticRegression_409084c8f7e4fc0950c0', name='regParam', doc='regularization parameter (>= 0).'): 2.0, Param(parent='LogisticRegression_409084c8f7e4fc0950c0', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 1.0, Param(parent='LogisticRegression_409084c8f7e4fc0950c0', name='maxIter', doc='max number of iterations (>= 0).'): 10}]\n"
     ]
    }
   ],
   "source": [
    "paramGrid_lr = ParamGridBuilder() \\\n",
    "                .addGrid(lr.regParam, [0.1, 0.5, 2.0]) \\\n",
    "                .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0])\\\n",
    "                .addGrid(lr.maxIter, [1, 5, 10])\\\n",
    "                .build()\n",
    "\n",
    "print(\"Param Grid: \" + str(paramGrid_lr))\n",
    "\n",
    "\n",
    "cv = CrossValidator(estimator=lr, estimatorParamMaps=paramGrid_lr, evaluator=evaluator, numFolds=5)\n",
    "cv_Model = cv.fit(trainingData)\n",
    "predictions_cv = cv_Model.transform(validationData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we apply a **Cross Validation** strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.84\n",
      "Means of metrics: ['0.7870', '0.8385', '0.8440', '0.7960', '0.8012', '0.8013', '0.5000', '0.5000', '0.5000', '0.7870', '0.8071', '0.8055', '0.5000', '0.5000', '0.5000', '0.5000', '0.5000', '0.5000', '0.7870', '0.7939', '0.7923', '0.5000', '0.5000', '0.5000', '0.5000', '0.5000', '0.5000']\n"
     ]
    }
   ],
   "source": [
    "# Before we had 0.6822 and now\n",
    "print(\"AUC: \" + str('%.2f' % evaluator.evaluate(predictions_cv)))\n",
    "\n",
    "# Means of model accuracy\n",
    "my_formatted_list_0 = [ '%.4f' % elem for elem in cv_Model.avgMetrics]\n",
    "print(\"Means of metrics: \" + str(my_formatted_list_0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Random Forest Model\n",
    "1. Define a `ParamGridBuilder` with `maxDepth`, `numTrees` and `maxIter` at least\n",
    "2. Define an `BinaryClassificationEvaluator` (You can use the above one)\n",
    "3. Using Cross Validation with a 5-fold `CrossValidator`\n",
    "\n",
    "Questions to answer:\n",
    "\n",
    "1. Have we improved the ROC-AUC?\n",
    "2. Which are the average ROC-AUC measurements in the different cross validation runs?\n",
    "3. Which are the parameters of the best model in the 5 k-fold runs?\n",
    "4. Which is the importance of the features?\n",
    "5. Print full description of model.\n",
    "6. Which is the ROC-AUC on validation dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+--------------------+\n",
      "|       rawPrediction|prediction|         probability|\n",
      "+--------------------+----------+--------------------+\n",
      "|[17.5036492929811...|       0.0|[0.87518246464905...|\n",
      "|[15.9001453105630...|       0.0|[0.79500726552815...|\n",
      "|[18.5729831633053...|       0.0|[0.92864915816526...|\n",
      "|[17.5648713232494...|       0.0|[0.87824356616247...|\n",
      "|[17.8065920678000...|       0.0|[0.89032960339000...|\n",
      "|[17.6247963053591...|       0.0|[0.88123981526795...|\n",
      "|[17.7153718041939...|       0.0|[0.88576859020969...|\n",
      "|[17.7893924023610...|       0.0|[0.88946962011805...|\n",
      "|[18.0690399272640...|       0.0|[0.90345199636320...|\n",
      "|[17.7307207284763...|       0.0|[0.88653603642381...|\n",
      "+--------------------+----------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(featuresCol = 'features', labelCol = 'label')\n",
    "\n",
    "rfModel = rf.fit(trainingData)\n",
    "\n",
    "predictions = rfModel.transform(validationData)\n",
    "\n",
    "predictions.select('rawPrediction', 'prediction', 'probability').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Area Under ROC 0.8418\n"
     ]
    }
   ],
   "source": [
    "print('Test Area Under ROC','%.4f' %  evaluator.evaluate(predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By setting the **paramGrid_rf** variable we define the set of different parameters we would like to test in order to tune our algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param Grid: [{Param(parent='RandomForestClassifier_4f3c859fd37a5bb0fee0', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 10, Param(parent='RandomForestClassifier_4f3c859fd37a5bb0fee0', name='numTrees', doc='Number of trees to train (>= 1).'): 10}, {Param(parent='RandomForestClassifier_4f3c859fd37a5bb0fee0', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 10, Param(parent='RandomForestClassifier_4f3c859fd37a5bb0fee0', name='numTrees', doc='Number of trees to train (>= 1).'): 20}, {Param(parent='RandomForestClassifier_4f3c859fd37a5bb0fee0', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 20, Param(parent='RandomForestClassifier_4f3c859fd37a5bb0fee0', name='numTrees', doc='Number of trees to train (>= 1).'): 10}, {Param(parent='RandomForestClassifier_4f3c859fd37a5bb0fee0', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 20, Param(parent='RandomForestClassifier_4f3c859fd37a5bb0fee0', name='numTrees', doc='Number of trees to train (>= 1).'): 20}]\n"
     ]
    }
   ],
   "source": [
    "paramGrid_rf = ParamGridBuilder() \\\n",
    "                .addGrid(rf.maxDepth, [10,20]) \\\n",
    "                .addGrid(rf.numTrees, [10,20]) \\\n",
    "                .build()\n",
    "\n",
    "print(\"Param Grid: \" + str(paramGrid_rf))\n",
    "\n",
    "\n",
    "cv_rf = CrossValidator(estimator=rf, estimatorParamMaps=paramGrid_rf, evaluator=evaluator, numFolds=5)\n",
    "cv_Model_rf = cv_rf.fit(trainingData)\n",
    "predictions_cv_rf = cv_Model_rf.transform(validationData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we apply a **Cross Validation** strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.92\n",
      "Means of metrics: ['0.8819', '0.8940', '0.8969', '0.9139']\n"
     ]
    }
   ],
   "source": [
    "# Before we had 0.6822 and now\n",
    "print(\"AUC: \" + str('%.2f' % evaluator.evaluate(predictions_cv_rf)))\n",
    "\n",
    "# Means of model accuracy\n",
    "my_formatted_list_1 = [ '%.4f' % elem for elem in cv_Model_rf.avgMetrics]\n",
    "print(\"Means of metrics: \" + str(my_formatted_list_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassificationModel (uid=RandomForestClassifier_4f3c859fd37a5bb0fee0) with 20 trees"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Best LR Model\n",
    "best_rf = cv_Model_rf.bestModel\n",
    "best_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Gradient Boosting Model\n",
    "1. Defining a `ParamGridBuilder` with `maxDepth`, `numTrees` and `maxIter` at least (You can use the above one)\n",
    "2. Define an `BinaryClassificationEvaluator` (You can use the above one)\n",
    "3. Using Cross Validation with a 5-fold `CrossValidator`\n",
    "\n",
    "Questions to answer:\n",
    "\n",
    "1. Have we improved the ROC-AUC?\n",
    "2. Which are the average ROC-AUC measurements in the different cross validation runs?\n",
    "3. Which are the parameters of the best model in the 5 k-fold runs?\n",
    "4. Which is the importance of the features?\n",
    "5. Print full description of model.\n",
    "6. Which is the ROC-AUC on validation dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+--------------------+\n",
      "|       rawPrediction|prediction|         probability|\n",
      "+--------------------+----------+--------------------+\n",
      "|[1.21978536359241...|       0.0|[0.91979542530482...|\n",
      "|[0.68210981968341...|       0.0|[0.79644464384408...|\n",
      "|[1.21377218285156...|       0.0|[0.91890372787360...|\n",
      "|[1.18802767301666...|       0.0|[0.91498308530803...|\n",
      "|[1.09383018413349...|       0.0|[0.89913592208174...|\n",
      "|[1.08212367091458...|       0.0|[0.89699265172697...|\n",
      "|[1.08212367091458...|       0.0|[0.89699265172697...|\n",
      "|[0.96125805639737...|       0.0|[0.87241875031202...|\n",
      "|[1.22489228877388...|       0.0|[0.92054569596139...|\n",
      "|[0.92417951653237...|       0.0|[0.86393431953011...|\n",
      "+--------------------+----------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gbt = GBTClassifier(maxIter=10)\n",
    "\n",
    "gbtModel = gbt.fit(trainingData)\n",
    "\n",
    "predictions_gbt = gbtModel.transform(validationData)\n",
    "\n",
    "predictions_gbt.select('rawPrediction', 'prediction', 'probability').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Area Under ROC 0.9339\n"
     ]
    }
   ],
   "source": [
    "print('Test Area Under ROC','%.4f' %  evaluator.evaluate(predictions_gbt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By setting the **paramGrid_gbt** variable we define the set of different parameters we would like to test in order to tune our algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param Grid: [{Param(parent='undefined', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 2, Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 10}, {Param(parent='undefined', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 2, Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 20}, {Param(parent='undefined', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 5, Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 10}, {Param(parent='undefined', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 5, Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 20}]\n"
     ]
    }
   ],
   "source": [
    "paramGrid_gbt = ParamGridBuilder() \\\n",
    "                    .addGrid(GBTClassifier.maxDepth, [2,5])\\\n",
    "                    .addGrid(GBTClassifier.maxIter, [10,20])\\\n",
    "                    .build()\n",
    "\n",
    "print(\"Param Grid: \" + str(paramGrid_gbt))\n",
    "\n",
    "\n",
    "cv_gbt = CrossValidator(estimator = gbt, estimatorParamMaps = paramGrid_gbt, evaluator = evaluator, numFolds=5)\n",
    "cv_Model_gbt = cv_gbt.fit(trainingData)\n",
    "predictions_cv_gbt = cv_Model_gbt.transform(validationData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we apply a **Cross Validation** strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.93\n",
      "Means of metrics: ['0.9249', '0.9249', '0.9249', '0.9249']\n"
     ]
    }
   ],
   "source": [
    "# Before we had 0.6822 and now\n",
    "print(\"AUC: \" + str('%.2f' % evaluator.evaluate(predictions_cv_gbt)))\n",
    "\n",
    "# Means of model accuracy\n",
    "my_formatted_list_2 = [ '%.4f' % elem for elem in cv_Model_gbt.avgMetrics]\n",
    "print(\"Means of metrics: \" + str(my_formatted_list_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GBTClassificationModel (uid=GBTClassifier_48c5ae11d972d687d0e9) with 10 trees"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best GBT Model\n",
    "best_gbt_model = cv_Model_gbt.bestModel\n",
    "best_gbt_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply your best model to send the predictions on test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- loan_amount: integer (nullable = true)\n",
      " |-- term: string (nullable = true)\n",
      " |-- interest_rate: decimal(10,0) (nullable = true)\n",
      " |-- monthly_payment: double (nullable = true)\n",
      " |-- employment_time: string (nullable = true)\n",
      " |-- home_ownership: string (nullable = true)\n",
      " |-- annual_income: double (nullable = true)\n",
      " |-- loan_purpose: string (nullable = false)\n",
      " |-- deliquency_past_2years: integer (nullable = false)\n",
      " |-- revolving_balance: integer (nullable = true)\n",
      " |-- revolving_utilization_rate: decimal(10,0) (nullable = true)\n",
      " |-- total_payment: double (nullable = false)\n",
      " |-- loan_status: integer (nullable = true)\n",
      " |-- termIndex: double (nullable = false)\n",
      " |-- termclassVec: vector (nullable = true)\n",
      " |-- employment_timeIndex: double (nullable = false)\n",
      " |-- employment_timeclassVec: vector (nullable = true)\n",
      " |-- home_ownershipIndex: double (nullable = false)\n",
      " |-- home_ownershipclassVec: vector (nullable = true)\n",
      " |-- loan_purposeIndex: double (nullable = false)\n",
      " |-- loan_purposeclassVec: vector (nullable = true)\n",
      " |-- label: double (nullable = false)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline(stages = stages)\n",
    "pipelineModel_final = pipeline.fit(testDF)\n",
    "testDF = pipelineModel_final.transform(testDF)\n",
    "selectedCols_final = testDF.columns\n",
    "testDF = testDF.select(selectedCols_final)\n",
    "testDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gbt = GBTClassifier(maxIter=10)\n",
    "\n",
    "gbtModel_final = gbt.fit(loanDF)\n",
    "\n",
    "predictions_final = gbtModel_final.transform(testDF)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o39894.collectToPython.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 6824.0 failed 1 times, most recent failure: Lost task 0.0 in stage 6824.0 (TID 13568, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function($anonfun$1: (vector) => vector)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$10$$anon$1.hasNext(WholeStageCodegenExec.scala:614)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:253)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:247)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:836)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:836)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:109)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: java.lang.IndexOutOfBoundsException: 35 not in [0,34)\n\tat breeze.linalg.SparseVector$mcD$sp.apply$mcD$sp(SparseVector.scala:74)\n\tat breeze.linalg.SparseVector$mcD$sp.apply(SparseVector.scala:73)\n\tat breeze.linalg.SparseVector$mcD$sp.apply(SparseVector.scala:49)\n\tat breeze.linalg.TensorLike$class.apply$mcID$sp(Tensor.scala:107)\n\tat breeze.linalg.SparseVector.apply$mcID$sp(SparseVector.scala:49)\n\tat org.apache.spark.ml.linalg.Vector$class.apply(Vectors.scala:102)\n\tat org.apache.spark.ml.linalg.SparseVector.apply(Vectors.scala:561)\n\tat org.apache.spark.ml.tree.ContinuousSplit.shouldGoLeft(Split.scala:161)\n\tat org.apache.spark.ml.tree.InternalNode.predictImpl(Node.scala:171)\n\tat org.apache.spark.ml.classification.GBTClassificationModel$$anonfun$5.apply(GBTClassifier.scala:325)\n\tat org.apache.spark.ml.classification.GBTClassificationModel$$anonfun$5.apply(GBTClassifier.scala:325)\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n\tat scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)\n\tat scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)\n\tat scala.collection.TraversableLike$class.map(TraversableLike.scala:234)\n\tat scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186)\n\tat org.apache.spark.ml.classification.GBTClassificationModel.margin(GBTClassifier.scala:325)\n\tat org.apache.spark.ml.classification.GBTClassificationModel.predictRaw(GBTClassifier.scala:280)\n\tat org.apache.spark.ml.classification.GBTClassificationModel.predictRaw(GBTClassifier.scala:212)\n\tat org.apache.spark.ml.classification.ProbabilisticClassificationModel$$anonfun$1.apply(ProbabilisticClassifier.scala:117)\n\tat org.apache.spark.ml.classification.ProbabilisticClassificationModel$$anonfun$1.apply(ProbabilisticClassifier.scala:116)\n\t... 16 more\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1651)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1639)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1638)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1638)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1872)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1821)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1810)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2034)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2055)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2074)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2099)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:945)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:944)\n\tat org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:297)\n\tat org.apache.spark.sql.Dataset$$anonfun$collectToPython$1.apply(Dataset.scala:3200)\n\tat org.apache.spark.sql.Dataset$$anonfun$collectToPython$1.apply(Dataset.scala:3197)\n\tat org.apache.spark.sql.Dataset$$anonfun$52.apply(Dataset.scala:3259)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:77)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3258)\n\tat org.apache.spark.sql.Dataset.collectToPython(Dataset.scala:3197)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.spark.SparkException: Failed to execute user defined function($anonfun$1: (vector) => vector)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$10$$anon$1.hasNext(WholeStageCodegenExec.scala:614)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:253)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:247)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:836)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:836)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:109)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\nCaused by: java.lang.IndexOutOfBoundsException: 35 not in [0,34)\n\tat breeze.linalg.SparseVector$mcD$sp.apply$mcD$sp(SparseVector.scala:74)\n\tat breeze.linalg.SparseVector$mcD$sp.apply(SparseVector.scala:73)\n\tat breeze.linalg.SparseVector$mcD$sp.apply(SparseVector.scala:49)\n\tat breeze.linalg.TensorLike$class.apply$mcID$sp(Tensor.scala:107)\n\tat breeze.linalg.SparseVector.apply$mcID$sp(SparseVector.scala:49)\n\tat org.apache.spark.ml.linalg.Vector$class.apply(Vectors.scala:102)\n\tat org.apache.spark.ml.linalg.SparseVector.apply(Vectors.scala:561)\n\tat org.apache.spark.ml.tree.ContinuousSplit.shouldGoLeft(Split.scala:161)\n\tat org.apache.spark.ml.tree.InternalNode.predictImpl(Node.scala:171)\n\tat org.apache.spark.ml.classification.GBTClassificationModel$$anonfun$5.apply(GBTClassifier.scala:325)\n\tat org.apache.spark.ml.classification.GBTClassificationModel$$anonfun$5.apply(GBTClassifier.scala:325)\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n\tat scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)\n\tat scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)\n\tat scala.collection.TraversableLike$class.map(TraversableLike.scala:234)\n\tat scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186)\n\tat org.apache.spark.ml.classification.GBTClassificationModel.margin(GBTClassifier.scala:325)\n\tat org.apache.spark.ml.classification.GBTClassificationModel.predictRaw(GBTClassifier.scala:280)\n\tat org.apache.spark.ml.classification.GBTClassificationModel.predictRaw(GBTClassifier.scala:212)\n\tat org.apache.spark.ml.classification.ProbabilisticClassificationModel$$anonfun$1.apply(ProbabilisticClassifier.scala:117)\n\tat org.apache.spark.ml.classification.ProbabilisticClassificationModel$$anonfun$1.apply(ProbabilisticClassifier.scala:116)\n\t... 16 more\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-fa4c23540006>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictions_final\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoPandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/Install_Spark/spark-2.3.2-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mtoPandas\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1966\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s\\n%s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_exception_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1967\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1968\u001b[0;31m             \u001b[0mpdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1969\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1970\u001b[0m             \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Install_Spark/spark-2.3.2-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mcollect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    464\u001b[0m         \"\"\"\n\u001b[1;32m    465\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSCCallSiteSync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m             \u001b[0msock_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollectToPython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBatchedSerializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPickleSerializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Install_Spark/spark-2.3.2-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Install_Spark/spark-2.3.2-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Install_Spark/spark-2.3.2-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o39894.collectToPython.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 6824.0 failed 1 times, most recent failure: Lost task 0.0 in stage 6824.0 (TID 13568, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function($anonfun$1: (vector) => vector)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$10$$anon$1.hasNext(WholeStageCodegenExec.scala:614)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:253)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:247)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:836)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:836)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:109)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: java.lang.IndexOutOfBoundsException: 35 not in [0,34)\n\tat breeze.linalg.SparseVector$mcD$sp.apply$mcD$sp(SparseVector.scala:74)\n\tat breeze.linalg.SparseVector$mcD$sp.apply(SparseVector.scala:73)\n\tat breeze.linalg.SparseVector$mcD$sp.apply(SparseVector.scala:49)\n\tat breeze.linalg.TensorLike$class.apply$mcID$sp(Tensor.scala:107)\n\tat breeze.linalg.SparseVector.apply$mcID$sp(SparseVector.scala:49)\n\tat org.apache.spark.ml.linalg.Vector$class.apply(Vectors.scala:102)\n\tat org.apache.spark.ml.linalg.SparseVector.apply(Vectors.scala:561)\n\tat org.apache.spark.ml.tree.ContinuousSplit.shouldGoLeft(Split.scala:161)\n\tat org.apache.spark.ml.tree.InternalNode.predictImpl(Node.scala:171)\n\tat org.apache.spark.ml.classification.GBTClassificationModel$$anonfun$5.apply(GBTClassifier.scala:325)\n\tat org.apache.spark.ml.classification.GBTClassificationModel$$anonfun$5.apply(GBTClassifier.scala:325)\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n\tat scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)\n\tat scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)\n\tat scala.collection.TraversableLike$class.map(TraversableLike.scala:234)\n\tat scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186)\n\tat org.apache.spark.ml.classification.GBTClassificationModel.margin(GBTClassifier.scala:325)\n\tat org.apache.spark.ml.classification.GBTClassificationModel.predictRaw(GBTClassifier.scala:280)\n\tat org.apache.spark.ml.classification.GBTClassificationModel.predictRaw(GBTClassifier.scala:212)\n\tat org.apache.spark.ml.classification.ProbabilisticClassificationModel$$anonfun$1.apply(ProbabilisticClassifier.scala:117)\n\tat org.apache.spark.ml.classification.ProbabilisticClassificationModel$$anonfun$1.apply(ProbabilisticClassifier.scala:116)\n\t... 16 more\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1651)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1639)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1638)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1638)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1872)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1821)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1810)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2034)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2055)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2074)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2099)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:945)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:944)\n\tat org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:297)\n\tat org.apache.spark.sql.Dataset$$anonfun$collectToPython$1.apply(Dataset.scala:3200)\n\tat org.apache.spark.sql.Dataset$$anonfun$collectToPython$1.apply(Dataset.scala:3197)\n\tat org.apache.spark.sql.Dataset$$anonfun$52.apply(Dataset.scala:3259)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:77)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3258)\n\tat org.apache.spark.sql.Dataset.collectToPython(Dataset.scala:3197)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.spark.SparkException: Failed to execute user defined function($anonfun$1: (vector) => vector)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$10$$anon$1.hasNext(WholeStageCodegenExec.scala:614)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:253)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:247)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:836)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:836)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:109)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\nCaused by: java.lang.IndexOutOfBoundsException: 35 not in [0,34)\n\tat breeze.linalg.SparseVector$mcD$sp.apply$mcD$sp(SparseVector.scala:74)\n\tat breeze.linalg.SparseVector$mcD$sp.apply(SparseVector.scala:73)\n\tat breeze.linalg.SparseVector$mcD$sp.apply(SparseVector.scala:49)\n\tat breeze.linalg.TensorLike$class.apply$mcID$sp(Tensor.scala:107)\n\tat breeze.linalg.SparseVector.apply$mcID$sp(SparseVector.scala:49)\n\tat org.apache.spark.ml.linalg.Vector$class.apply(Vectors.scala:102)\n\tat org.apache.spark.ml.linalg.SparseVector.apply(Vectors.scala:561)\n\tat org.apache.spark.ml.tree.ContinuousSplit.shouldGoLeft(Split.scala:161)\n\tat org.apache.spark.ml.tree.InternalNode.predictImpl(Node.scala:171)\n\tat org.apache.spark.ml.classification.GBTClassificationModel$$anonfun$5.apply(GBTClassifier.scala:325)\n\tat org.apache.spark.ml.classification.GBTClassificationModel$$anonfun$5.apply(GBTClassifier.scala:325)\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n\tat scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)\n\tat scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)\n\tat scala.collection.TraversableLike$class.map(TraversableLike.scala:234)\n\tat scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186)\n\tat org.apache.spark.ml.classification.GBTClassificationModel.margin(GBTClassifier.scala:325)\n\tat org.apache.spark.ml.classification.GBTClassificationModel.predictRaw(GBTClassifier.scala:280)\n\tat org.apache.spark.ml.classification.GBTClassificationModel.predictRaw(GBTClassifier.scala:212)\n\tat org.apache.spark.ml.classification.ProbabilisticClassificationModel$$anonfun$1.apply(ProbabilisticClassifier.scala:117)\n\tat org.apache.spark.ml.classification.ProbabilisticClassificationModel$$anonfun$1.apply(ProbabilisticClassifier.scala:116)\n\t... 16 more\n"
     ]
    }
   ],
   "source": [
    "predictions_final.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MySparkContext.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
