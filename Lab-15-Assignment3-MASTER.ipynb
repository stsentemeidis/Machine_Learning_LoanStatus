{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 16 Assignment 3 - Group Assignment - Group O-1-7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When creating ML models, the concept of efficiency has three sides:\n",
    "1. The time dedicated by the analyst to build the model\n",
    "2. The computer time and resources needed by the final model\n",
    "3. The accuracy of the final model\n",
    "\n",
    "Efficiency is a combination of all\n",
    "\n",
    "In this assignment, you are asked to be efficient. Spark is the best tool to build models over massive datasets\n",
    "\n",
    "If you need to create Spark+Python Machine Learning models that \"run fast\" on the  cluster, you must avoid using Python code or working with RRD+python. Try to use  the already existing methods that do what you need (do not reinvent the wheel).\n",
    "\n",
    "Therefore try to use the implemented object+methods inside the Spark SQL and ML modules. They are very fast, because it is compiled Java/Scala code. Try to use: DataFrames, Feature Transfomers, Estimators, Pipelines, GridSearch, CV, ...\n",
    "\n",
    "For this assignment, you are asked to create a classification model that:\n",
    "1. Uses the variables in the dataset (train.csv) to predict label \"loan_status\"\n",
    "2. Write a python scripts that:\n",
    "    - Reads the \"train.csv\" and \"test.csv\" files, transform and select variables as you wish.\n",
    "    - Train/fit your model using the \"train.csv\".\n",
    "    - Predict your model on the \"test.csv\" ( you should generate a file with your predictions).\n",
    "    - I will use a different test dataset (with the true loan_status).\n",
    "\n",
    "Your work will be evaluated under the following scoring schema\n",
    "- (40%) ETL process\n",
    "- (40%) Model train process\n",
    "- (10%) Code Readability \n",
    "- (10%) AUC on the test set (at least 50%)\n",
    "\n",
    "Enjoy it and best of luck!!\n",
    "\n",
    "This Assignment is based on kaggle competition https://www.kaggle.com/c/loan-default-prediction from where a sub-dataset has been taken."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**train.csv** - the training set (to use for building a model)\n",
    "\n",
    "**test.csv** - the test set (to use for applying predictings)\n",
    "\n",
    "**sample_submission.csv** - a template for the submission file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Description (contained in LendingClub_DataDescription.csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ID**: A unique LC assigned ID for the loan listing.\n",
    "\n",
    "**loan_amnt**: The listed amount of the loan applied for by the borrower. If at some point in time, the credit department reduces the loan amount, then it will be reflected in this value.\n",
    "\n",
    "**loan_status**: Current status of the loan (**Target**: 1 = Charged Off, 0 = Fully Paid).\n",
    "\n",
    "**term**: The number of payments on the loan. Values are in months and can be either 36 or 60.\n",
    "\n",
    "**int_rate**: Interest Rate on the loan.\n",
    "\n",
    "**installment**: The monthly payment owed by the borrower if the loan originates.\n",
    "\n",
    "**emp_length**: Employment length in years. Possible values are between 0 and 10 where 0 means less than one year and 10 means ten or more years.\n",
    "\n",
    "**home_ownership**: The home ownership status provided by the borrower during registration. Our values are: OTHER/NONE, MORTGAGE, OWN, RENT.\n",
    "\n",
    "**annual_inc**: The self-reported annual income provided by the borrower during registration.\n",
    "\n",
    "**purpose**: A category provided by the borrower for the loan request.\n",
    "\n",
    "**title**: The loan title provided by the borrower.\n",
    "\n",
    "**STATE**: The state provided by the borrower in the loan application.\n",
    "\n",
    "**delinq_2yrs**: The number of 30+ days past-due incidences of delinquency in the borrower's credit file for the past 2 years.\n",
    "\n",
    "**revol_bal**: Total credit revolving balance.\n",
    "\n",
    "**revol_util**: Revolving line utilization rate, or the amount of credit the borrower is using relative to all available revolving credit.\n",
    "\n",
    "**total_pymnt**: Indicates total payment at the end of the loan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ['SPARK_HOME'] = \"/Users/stavrostsentemeidis/Desktop/Install_Spark/spark-2.3.2-bin-hadoop2.7/\"\n",
    "\n",
    "# Create a variable for our root path\n",
    "SPARK_HOME = os.environ['SPARK_HOME']\n",
    "\n",
    "#Add the following paths to the system path. Please check your installation\n",
    "#to make sure that these zip files actually exist. The names might change\n",
    "#as versions change.\n",
    "sys.path.insert(0,os.path.join(SPARK_HOME,\"python\"))\n",
    "sys.path.insert(0,os.path.join(SPARK_HOME,\"python\",\"lib\"))\n",
    "sys.path.insert(0,os.path.join(SPARK_HOME,\"python\",\"lib\",\"pyspark.zip\"))\n",
    "sys.path.insert(0,os.path.join(SPARK_HOME,\"python\",\"lib\",\"py4j-0.10.7-src.zip\"))\n",
    "\n",
    "#Initialize SparkSession and SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import avg,countDistinct\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.functions import isnan, when, count\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.classification import RandomForestClassificationModel, RandomForestClassifier\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator, CrossValidatorModel\n",
    "from pyspark.ml.param import Params\n",
    "from pyspark.ml import Pipeline, PipelineModel\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import OneHotEncoderEstimator\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "from pyspark.ml.feature import MinMaxScaler\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "#Create a Spark Session\n",
    "MySparkSession = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(\"local[2]\") \\\n",
    "    .appName(\"MiPrimer\") \\\n",
    "    .config(\"spark.executor.memory\", \"6g\") \\\n",
    "    .config(\"spark.cores.max\",\"4\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "\n",
    "#Get the Spark Context from Spark Session    \n",
    "MySparkContext = MySparkSession.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading and Displaying Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loanDF = MySparkSession.read.format('csv') \\\n",
    "                .option(\"inferSchema\", \"true\") \\\n",
    "                .option(\"delimiter\", \";\") \\\n",
    "                .option('header','true') \\\n",
    "                .load('../data/train.csv') \n",
    "\n",
    "testDF = MySparkSession.read.format('csv') \\\n",
    "                .option(\"inferSchema\", \"true\") \\\n",
    "                .option(\"delimiter\", \";\") \\\n",
    "                .option('header','true') \\\n",
    "                .load('../data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loanDF.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "testDF.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA | Null Values | Cross Table Distribution | Covariances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('loanDF:')\n",
    "loanDF.printSchema()\n",
    "print('testDF:')\n",
    "testDF.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Renaming | Describing | Changing Data Type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formatting numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loanDF = loanDF.withColumn('int_rate', regexp_replace('int_rate', '%', ''))\n",
    "loanDF = loanDF.withColumn('title', regexp_replace('title', '.', ''))\n",
    "loanDF = loanDF.withColumn(\"int_rate\", loanDF[\"int_rate\"].cast(\"decimal(10,0)\"))\n",
    "loanDF = loanDF.withColumn(\"revol_util\", loanDF[\"revol_util\"].cast(\"decimal(10,0)\"))\n",
    "\n",
    "testDF = testDF.withColumn('int_rate', regexp_replace('int_rate', '%', ''))\n",
    "testDF = testDF.withColumn('title', regexp_replace('title', '.', ''))\n",
    "testDF = testDF.withColumn(\"int_rate\", testDF[\"int_rate\"].cast(\"decimal(10,0)\"))\n",
    "testDF = testDF.withColumn(\"revol_util\", testDF[\"revol_util\"].cast(\"decimal(10,0)\"))\n",
    "\n",
    "loanDF = loanDF.withColumn('emp_length', regexp_replace('emp_length', 'n/a', 'unknown'))\n",
    "testDF = testDF.withColumn('emp_length', regexp_replace('emp_length', 'n/a', 'unknown'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Renaming columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loanDF = loanDF.withColumnRenamed(\"ID\",\"id\")\n",
    "loanDF = loanDF.withColumnRenamed(\"loan_amnt\",\"loan_amount\")\n",
    "loanDF = loanDF.withColumnRenamed(\"term\",\"term\")\n",
    "loanDF = loanDF.withColumnRenamed(\"home_ownership\",\"home_ownership\")\n",
    "loanDF = loanDF.withColumnRenamed(\"int_rate\",\"interest_rate\")\n",
    "loanDF = loanDF.withColumnRenamed(\"installment\",\"monthly_payment\")\n",
    "loanDF = loanDF.withColumnRenamed(\"emp_length\",\"employment_time\")\n",
    "loanDF = loanDF.withColumnRenamed(\"delinq_2yrs\",\"deliquency_past_2years\")\n",
    "loanDF = loanDF.withColumnRenamed(\"revol_bal\",\"revolving_balance\")\n",
    "loanDF = loanDF.withColumnRenamed(\"revol_util\",\"revolving_utilization_rate\")\n",
    "loanDF = loanDF.withColumnRenamed(\"total_pymnt\",\"total_payment\")\n",
    "loanDF = loanDF.withColumnRenamed(\"purpose\",\"loan_purpose\")\n",
    "loanDF = loanDF.withColumnRenamed(\"annual_inc\",\"annual_income\")\n",
    "loanDF = loanDF.withColumnRenamed(\"STATE\",\"state\")\n",
    "loanDF = loanDF.withColumnRenamed(\"installment\",\"installment\")\n",
    "loanDF = loanDF.withColumnRenamed(\"loan_status\",\"loan_status\")\n",
    "\n",
    "\n",
    "testDF = testDF.withColumnRenamed(\"ID\",\"id\")\n",
    "testDF = testDF.withColumnRenamed(\"loan_amnt\",\"loan_amount\")\n",
    "testDF = testDF.withColumnRenamed(\"term\",\"term\")\n",
    "testDF = testDF.withColumnRenamed(\"home_ownership\",\"home_ownership\")\n",
    "testDF = testDF.withColumnRenamed(\"int_rate\",\"interest_rate\")\n",
    "testDF = testDF.withColumnRenamed(\"installment\",\"monthly_payment\")\n",
    "testDF = testDF.withColumnRenamed(\"emp_length\",\"employment_time\")\n",
    "testDF = testDF.withColumnRenamed(\"delinq_2yrs\",\"deliquency_past_2years\")\n",
    "testDF = testDF.withColumnRenamed(\"revol_bal\",\"revolving_balance\")\n",
    "testDF = testDF.withColumnRenamed(\"revol_util\",\"revolving_utilization_rate\")\n",
    "testDF = testDF.withColumnRenamed(\"total_pymnt\",\"total_payment\")\n",
    "testDF = testDF.withColumnRenamed(\"purpose\",\"loan_purpose\")\n",
    "testDF = testDF.withColumnRenamed(\"annual_inc\",\"annual_income\")\n",
    "testDF = testDF.withColumnRenamed(\"STATE\",\"state\")\n",
    "testDF = testDF.withColumnRenamed(\"installment\",\"installment\")\n",
    "testDF = testDF.withColumnRenamed(\"loan_status\",\"loan_status\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summarizing `loanDF`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "numeric_df = ['loan_amount','interest_rate', 'monthly_payment','annual_income', 'deliquency_past_2years',\n",
    "              'total_payment','revolving_balance','revolving_utilization_rate']\n",
    "\n",
    "categorical_Df = ['term','employment_time', 'home_ownership', 'loan_purpose', 'title','state']\n",
    "\n",
    "loanDF.describe('loan_amount','term','interest_rate','title','employment_time','home_ownership').show()\n",
    "loanDF.describe('annual_income','loan_purpose','monthly_payment','state','deliquency_past_2years').show()\n",
    "loanDF.describe('revolving_balance','revolving_utilization_rate','total_payment','loan_status').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display(testDF.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Rows in loanDF:',loanDF.count())\n",
    "print('Rows in testDF:',testDF.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_loanDF = loanDF.na.drop() \n",
    "remove_testDF = testDF.na.drop()  \n",
    "print('Rows in loanDF with NAs:', loanDF.count() - remove_loanDF.count())\n",
    "print('Rows in loanDF with no NAs:',remove_loanDF.count())\n",
    "print()\n",
    "print('Rows in testDF with NAs:', testDF.count() - remove_testDF.count())\n",
    "print('Rows in testDF with no NAs:',remove_testDF.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Table Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross tables distribution\n",
    "loanDF.stat.crosstab('employment_time', 'term').show()\n",
    "loanDF.stat.crosstab('home_ownership', 'term').show()\n",
    "loanDF.stat.crosstab('loan_purpose', 'term').show()\n",
    "loanDF.stat.crosstab('state', 'term').show()\n",
    "loanDF.stat.crosstab('home_ownership', 'employment_time').show()\n",
    "loanDF.stat.crosstab('loan_purpose', 'employment_time').show()\n",
    "loanDF.stat.crosstab('state', 'employment_time').show()\n",
    "loanDF.stat.crosstab('loan_purpose', 'home_ownership').show()\n",
    "loanDF.stat.crosstab('state', 'home_ownership').show()\n",
    "loanDF.stat.crosstab('state', 'loan_purpose').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Covariance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in numeric_df:\n",
    "    for j in numeric_df:\n",
    "        print('Covariance of ' + i + ' and '+ j )\n",
    "        print(loanDF.stat.cov(i, j))\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a better readability, we plotted the correlation matrix and a pairplot using pandas dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt #Plotting - version 3.0.2\n",
    "import seaborn as sns #Plotting - version 0.9.0\n",
    "sns.set(style='white')\n",
    "\n",
    "loanDF_corr = loanDF.toPandas().copy()\n",
    "loanDF_corr.interest_rate = loanDF_corr.interest_rate.astype(float)\n",
    "loanDF_corr.revolving_utilization_rate = loanDF_corr.interest_rate.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(loanDF_corr.corr(), \n",
    "            cmap=sns.diverging_palette(220, 20, n=7), vmax=1.0, vmin=-1.0, linewidths=0.1,\n",
    "            annot=True, annot_kws={\"size\": 8}, square=True)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loanDF_pair = loanDF.toPandas().copy()\n",
    "loanDF_pair.interest_rate = loanDF_pair.interest_rate.astype(float)\n",
    "loanDF_pair.revolving_utilization_rate = loanDF_pair.interest_rate.astype(float)\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "sns.pairplot(data = loanDF_pair, diag_kind = 'kde', plot_kws = {'alpha':0.3, 's':5})\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ETL summary |  Spark code for Imputing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we present the steps we decided to follow during our EDA in order to prepare our dataset for our machine learning implementation. It is worth mentioning that some of the steps had to be included in the previous part of the assignment in order to have a complete overview of the *cross table distributions* and the *covariances*.\n",
    "\n",
    "1. **interest_rate** : remove special % character and change datatype from *string* to *decimal*.\n",
    "2. **revol_util** : change datatype from *string* to *decimal*.\n",
    "3. **Rename** columns to be better represented.\n",
    "4. **Trim** the variable title as there are multiple unnecessary dots.\n",
    "5. **Checkin for Na**: \n",
    "    1. Number of rows with NA for *loanDF*:    29755\n",
    "    2. Number of rows without NA for *loanDF*: 27773\n",
    "    3. Number of rows with NA for *testDF*:    10024\n",
    "    4. Number of rows without NA for *testDF*: 9116\n",
    "6. **Filling Na values**:\n",
    "    1. **title** :                      unknown\n",
    "    2. **loan_purpose** :               unknown\n",
    "    3. **state** :                      unknown\n",
    "    4. **deliquency_past_2years** :     -1\n",
    "    5. **revolving_balance** :          13350.529071398512 (avg)\n",
    "    6. **revolving_utilization_rate** : 0.5054 (avg)\n",
    "    7. **total_payment** :              12143.791490200982 (avg)\n",
    "7. **Drop** variables *title* and *state* cause they have too many unique values that cannot be grouped in order to apply one hot coding.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Imputing Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_revolving_balance = loanDF.agg(avg(col(\"revolving_balance\"))).collect()[0][0]\n",
    "mean_revolving_utilization_rate = float(loanDF.agg(avg(col(\"revolving_utilization_rate\"))).collect()[0][0])\n",
    "mean_total_payment = loanDF.agg(avg(col(\"total_payment\"))).collect()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loanDF = loanDF.na.fill({'title': 'unknown', 'loan_purpose': 'unknown', 'state': 'unknown',\n",
    "                         'deliquency_past_2years':-1,'revolving_balance':mean_revolving_balance,\n",
    "                         'revolving_utilization_rate': mean_revolving_utilization_rate,\n",
    "                         'total_payment': mean_total_payment})\n",
    "\n",
    "testDF = testDF.na.fill({'title': 'unknown', 'loan_purpose': 'unknown', 'state': 'unknown',\n",
    "                         'employment_time':'unknown',\n",
    "                         'deliquency_past_2years':-1,'revolving_balance':mean_revolving_balance,\n",
    "                         'revolving_utilization_rate': mean_revolving_utilization_rate,\n",
    "                         'total_payment': mean_total_payment})\n",
    "\n",
    "print('Rows in loanDF:',loanDF.count())\n",
    "print('Rows in testDF:',testDF.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in numeric_df:\n",
    "    mean_0, sttdev_0 = loanDF.select(mean(i), stddev(i)).first()\n",
    "    loanDF = loanDF.withColumn(i + '_scaled', (col(i) - mean_0) / sttdev_0)    \n",
    "    \n",
    "for i in numeric_df:\n",
    "    mean_0, sttdev_0 = testDF.select(mean(i), stddev(i)).first()\n",
    "    testDF = testDF.withColumn(i + '_scaled', (col(i) - mean_0) / sttdev_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Double checking final clean dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loanDF.printSchema()\n",
    "testDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loanDF = loanDF.drop('loan_amount','interest_rate','monthly_payment','annual_income','deliquency_past_2years',\n",
    "                     'total_payment','revolving_balance','revolving_utilization_rate')\n",
    "\n",
    "testDF = testDF.drop('loan_amount','interest_rate','monthly_payment','annual_income','deliquency_past_2years',\n",
    "                     'total_payment','revolving_balance','revolving_utilization_rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loanDF.printSchema()\n",
    "testDF.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking all our columns to verify that we have:\n",
    "   * Distinct user id so we do not need to group by.\n",
    "   * Clean data format.\n",
    "   * Clean cell values, (for example no Na and nan, which mean the same thing) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loanDF.describe('loan_amount_scaled','term','interest_rate_scaled','title','employment_time','home_ownership').show()\n",
    "loanDF.describe('annual_income_scaled','loan_purpose','monthly_payment_scaled','state','deliquency_past_2years_scaled').show()\n",
    "loanDF.describe('revolving_balance_scaled','revolving_utilization_rate_scaled').show()\n",
    "loanDF.describe('total_payment_scaled','loan_status').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# we have unique id = number of rows of dataset, so we do not need to group by.\n",
    "for i in loanDF.columns:\n",
    "    print(loanDF.select(i).distinct().count())\n",
    "    print(loanDF.select(i).distinct().show())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this stage we check the final structure of the table and we also decide to drop the **title** and **state** feature as they have so many different values, which makes it difficult to use in our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loanDF = loanDF.drop(\"title\", 'state')\n",
    "testDF = testDF.drop(\"title\", 'state')\n",
    "loanDF.printSchema()\n",
    "testDF.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Pipeline | Split train/test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this stage we make the following adjustments:\n",
    "\n",
    "1. We keep the **total_amount** column and we discard the **monthly payment**, because of high correlation between the 2. The reason for keeipng the total amount is based more on a business perspective.\n",
    "2. We keep the **interest_rate** column and we discard the **revolving_utilization_rate**, as they are totally correlated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoricalColumns = ['term', 'employment_time', 'home_ownership', 'loan_purpose']\n",
    "stages = []\n",
    "\n",
    "for categoricalCol in categoricalColumns:\n",
    "    stringIndexer = StringIndexer(inputCol = categoricalCol, outputCol = categoricalCol + 'Index')\n",
    "    encoder = OneHotEncoderEstimator(inputCols=[stringIndexer.getOutputCol()], outputCols=[categoricalCol + \"classVec\"])\n",
    "    stages += [stringIndexer, encoder]\n",
    "    \n",
    "label_stringIdx = StringIndexer(inputCol = 'loan_status', outputCol = 'label')\n",
    "\n",
    "stages += [label_stringIdx]\n",
    "\n",
    "numericCols = ['loan_amount_scaled', 'interest_rate_scaled', 'annual_income_scaled', 'deliquency_past_2years_scaled', \n",
    "               'revolving_balance_scaled']\n",
    "assemblerInputs = [c + \"classVec\" for c in categoricalColumns] + numericCols\n",
    "assembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")\n",
    "\n",
    "stages += [assembler]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it is time for use to define the pipeline we are going to use for all the models that are about to be tested including:\n",
    "1. **Logistic Regression**\n",
    "2. **Random Forest**\n",
    "3. **Gradient Tree Boosting**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages = stages)\n",
    "pipelineModel = pipeline.fit(loanDF)\n",
    "loanDF = pipelineModel.transform(loanDF)\n",
    "selectedCols = ['features'] + loanDF.columns\n",
    "loanDF = loanDF.select(selectedCols)\n",
    "loanDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(loanDF.take(5), columns=loanDF.columns).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainingData, validationData) = loanDF.randomSplit([0.7, 0.3], seed=100)\n",
    "print(\"Training Dataset Count: \" + str(trainingData.count()))\n",
    "print(\"Test Dataset Count: \" + str(validationData.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection | Chi-Square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Feature selection using chisquareSelector\n",
    "# from pyspark.ml.feature import ChiSqSelector\n",
    "\n",
    "# css = ChiSqSelector(featuresCol='features',outputCol='Aspect',labelCol='label',fpr=0.05)\n",
    "# train = css.fit(trainingData).transform(trainingData)\n",
    "# test = css.fit(validationData).transform(validationData)\n",
    "# test.select(\"Aspect\").show(5,truncate=False)\n",
    "\n",
    "# https://medium.com/@dhiraj.p.rai/logistic-regression-in-spark-ml-8a95b5f5434c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regresion Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric Function for TrainingSummary Output \n",
    "1. Area under ROC\n",
    "2. False Positive Rate By Label\n",
    "3. True Positive Rate By Label\n",
    "4. Precision By Label\n",
    "5. Recall By Label\n",
    "6. fMeasure By Label\n",
    "7. Accuracy\n",
    "8. False Positive Rate\n",
    "9. True Positive Rate\n",
    "10. fMeasure\n",
    "11. Precision\n",
    "12. Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(trainingSummary):  \n",
    "    my_formatted_list_FP = [ '%.2f' % elem for elem in trainingSummary.truePositiveRateByLabel]\n",
    "    my_formatted_list_TP = [ '%.2f' % elem for elem in trainingSummary.precisionByLabel]\n",
    "    my_formatted_list_P = [ '%.2f' % elem for elem in trainingSummary.falsePositiveRateByLabel]\n",
    "    my_formatted_list_R = [ '%.2f' % elem for elem in trainingSummary.recallByLabel]\n",
    "    \n",
    "    print(\"AUC: \" + str(\"%.2f\" % trainingSummary.areaUnderROC))\n",
    "    print('')\n",
    "    print(\"False Positive Rate by Label: \" + str(my_formatted_list_FP))\n",
    "    print('')\n",
    "    print(\"True Positive Rate by Label: \" + str(my_formatted_list_P))\n",
    "    print('')\n",
    "    print(\"Precision by Label: \" + str(my_formatted_list_TP))\n",
    "    print('')\n",
    "    print(\"Recall by Label: \" + str(my_formatted_list_R))\n",
    "    print('')\n",
    "    print(\"fMeasure by Label: \" + str(trainingSummary.fMeasureByLabel))\n",
    "    print('')\n",
    "    print(\"Accuracy: \" + str(\"%.2f\" %trainingSummary.accuracy))\n",
    "    print('')\n",
    "    print(\"False Positive Rate: \" + str(\"%.2f\" %trainingSummary.weightedFalsePositiveRate))\n",
    "    print('')\n",
    "    print(\"True Positive Rate: \" + str(\"%.2f\" %trainingSummary.weightedTruePositiveRate)) \n",
    "    print('')\n",
    "    print(\"fMeasure: \" + str(trainingSummary.weightedFMeasure))\n",
    "    print('')\n",
    "    print(\"Precision: \" + str(\"%.2f\" %trainingSummary.weightedPrecision))\n",
    "    print('')\n",
    "    print(\"Recall: \" + str(\"%.2f\" %trainingSummary.weightedRecall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regresion Base Model | Metrics Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = BinaryClassificationEvaluator() \\\n",
    "                .setLabelCol(\"label\") \\\n",
    "                .setRawPredictionCol(\"rawPrediction\")\n",
    "\n",
    "print(\"We are using metric: \" + evaluator.getMetricName())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression(featuresCol = 'features', labelCol = 'label', maxIter=10)\n",
    "lrModel = lr.fit(trainingData)\n",
    "trainingSummary = lrModel.summary\n",
    "metrics(trainingSummary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_lr = lrModel.transform(validationData)\n",
    "predictions_lr.select('rawPrediction', 'prediction', 'probability').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Test Area Under ROC','%.4f' %  evaluator.evaluate(predictions_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configurations to Improve\n",
    "1. Using a `weight column` in our Logistic Regression Model (Take into account we are working with a unbalanced dataset)\n",
    "2. Define a `ParamGridBuilder` with `regParam`, `elasticNetParam` and `maxIter` at least\n",
    "3. Define an `BinaryClassificationEvaluator`\n",
    "4. Using Cross Validation with a 5-fold `CrossValidator`\n",
    "\n",
    "Questions to answer:\n",
    "1. Have we improved the ROC-AUC?\n",
    "2. Which are the average ROC-AUC measurements in the different cross validation runs?\n",
    "3. Which are the parameters of the best model in the 5 k-fold runs?\n",
    "4. Which are the metrics of the best model (training) in the 5 k-fold runs? (Use the function above)\n",
    "5. Which is the ROC-AUC on validation dataset?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loanDF.groupBy(\"label\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BalancingRatio= 25530/29755\n",
    "print('BalancingRatio = {}'.format(BalancingRatio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingData = trainingData.withColumn(\"classWeights\", when(trainingData.label == 1,BalancingRatio).otherwise(1-BalancingRatio))\n",
    "trainingData.select(\"classWeights\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_weighted = LogisticRegression(featuresCol = 'features', labelCol = 'label', maxIter=10, weightCol=\"classWeights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = BinaryClassificationEvaluator() \\\n",
    "                .setLabelCol(\"label\") \\\n",
    "                .setRawPredictionCol(\"rawPrediction\")\n",
    "\n",
    "print(\"We are using metric: \" + evaluator.getMetricName())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By setting the **paramGrid_lr** variable we define the set of different parameters we would like to test in order to tune our algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramGrid_lr = ParamGridBuilder() \\\n",
    "                .addGrid(lr_weighted.regParam, [0.1, 0.5, 2.0, 5.0, 7.5, 10.0]) \\\n",
    "                .addGrid(lr_weighted.elasticNetParam, [0.0, 0.25, 0.5, 0.75, 1.0])\\\n",
    "                .addGrid(lr_weighted.maxIter, [1, 5, 10, 15, 25])\\\n",
    "                .build()\n",
    "\n",
    "print(\"Param Grid: \" + str(paramGrid_lr))\n",
    "\n",
    "\n",
    "cv = CrossValidator(estimator=lr_weighted, estimatorParamMaps=paramGrid_lr, evaluator=evaluator, numFolds=5)\n",
    "cv_Model = cv.fit(trainingData)\n",
    "predictions_cv = cv_Model.transform(validationData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we apply a **Cross Validation** strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before we had 0.6878 and now\n",
    "print(\"AUC: \" + str('%.4f' % evaluator.evaluate(predictions_cv)))\n",
    "\n",
    "# Means of model accuracy\n",
    "my_formatted_list_0 = [ '%.4f' % elem for elem in cv_Model.avgMetrics]\n",
    "print(\"Means of metrics: \" + str(my_formatted_list_0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Model\n",
    "1. Define a `ParamGridBuilder` with `maxDepth`, `numTrees` and `maxIter` at least\n",
    "2. Define an `BinaryClassificationEvaluator` (You can use the above one)\n",
    "3. Using Cross Validation with a 5-fold `CrossValidator`\n",
    "\n",
    "Questions to answer:\n",
    "\n",
    "1. Have we improved the ROC-AUC?\n",
    "2. Which are the average ROC-AUC measurements in the different cross validation runs?\n",
    "3. Which are the parameters of the best model in the 5 k-fold runs?\n",
    "4. Which is the importance of the features?\n",
    "5. Print full description of model.\n",
    "6. Which is the ROC-AUC on validation dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(featuresCol = 'features', labelCol = 'label')\n",
    "\n",
    "rfModel = rf.fit(trainingData)\n",
    "\n",
    "predictions = rfModel.transform(validationData)\n",
    "\n",
    "predictions.select('rawPrediction', 'prediction', 'probability').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Test Area Under ROC','%.4f' %  evaluator.evaluate(predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By setting the **paramGrid_rf** variable we define the set of different parameters we would like to test in order to tune our algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "paramGrid_rf = ParamGridBuilder() \\\n",
    "                .addGrid(rf.maxDepth, [10, 20, 30]) \\\n",
    "                .addGrid(rf.numTrees, [10, 20, 30]) \\\n",
    "                .build()\n",
    "\n",
    "print(\"Param Grid: \" + str(paramGrid_rf))\n",
    "\n",
    "\n",
    "cv_rf = CrossValidator(estimator=rf, estimatorParamMaps=paramGrid_rf, evaluator=evaluator, numFolds=5)\n",
    "cv_Model_rf = cv_rf.fit(trainingData)\n",
    "predictions_cv_rf = cv_Model_rf.transform(validationData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we apply a **Cross Validation** strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before we had 0.6813 and now\n",
    "print(\"AUC: \" + str('%.4f' % evaluator.evaluate(predictions_cv_rf)))\n",
    "\n",
    "# Means of model accuracy\n",
    "my_formatted_list_1 = [ '%.4f' % elem for elem in cv_Model_rf.avgMetrics]\n",
    "print(\"Means of metrics: \" + str(my_formatted_list_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Best LR Model\n",
    "best_rf = cv_Model_rf.bestModel\n",
    "best_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Gradient Boosting Model\n",
    "1. Defining a `ParamGridBuilder` with `maxDepth`, `numTrees` and `maxIter` at least (You can use the above one)\n",
    "2. Define an `BinaryClassificationEvaluator` (You can use the above one)\n",
    "3. Using Cross Validation with a 5-fold `CrossValidator`\n",
    "\n",
    "Questions to answer:\n",
    "\n",
    "1. Have we improved the ROC-AUC?\n",
    "2. Which are the average ROC-AUC measurements in the different cross validation runs?\n",
    "3. Which are the parameters of the best model in the 5 k-fold runs?\n",
    "4. Which is the importance of the features?\n",
    "5. Print full description of model.\n",
    "6. Which is the ROC-AUC on validation dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbt = GBTClassifier(maxIter=10)\n",
    "\n",
    "gbtModel = gbt.fit(trainingData)\n",
    "\n",
    "predictions_gbt = gbtModel.transform(validationData)\n",
    "\n",
    "predictions_gbt.select('rawPrediction', 'prediction', 'probability').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Test Area Under ROC','%.4f' %  evaluator.evaluate(predictions_gbt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By setting the **paramGrid_gbt** variable we define the set of different parameters we would like to test in order to tune our algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramGrid_gbt = ParamGridBuilder() \\\n",
    "                    .addGrid(GBTClassifier.maxDepth, [2,5])\\\n",
    "                    .addGrid(GBTClassifier.maxIter, [10,20])\\\n",
    "                    .build()\n",
    "\n",
    "print(\"Param Grid: \" + str(paramGrid_gbt))\n",
    "\n",
    "\n",
    "cv_gbt = CrossValidator(estimator = gbt, estimatorParamMaps = paramGrid_gbt, evaluator = evaluator, numFolds=5)\n",
    "cv_Model_gbt = cv_gbt.fit(trainingData)\n",
    "predictions_cv_gbt = cv_Model_gbt.transform(validationData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we apply a **Cross Validation** strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before we had 0.6822 and now\n",
    "print(\"AUC: \" + str('%.4f' % evaluator.evaluate(predictions_cv_gbt)))\n",
    "\n",
    "# Means of model accuracy\n",
    "my_formatted_list_2 = [ '%.4f' % elem for elem in cv_Model_gbt.avgMetrics]\n",
    "print(\"Means of metrics: \" + str(my_formatted_list_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best GBT Model\n",
    "best_gbt_model = cv_Model_gbt.bestModel\n",
    "best_gbt_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply your best model to send the predictions on test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDF2 = pipelineModel.transform(testDF)\n",
    "selectedCols = testDF2.columns\n",
    "testDF2 = testDF2.select(selectedCols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# lr = LogisticRegression(featuresCol = 'features', labelCol = 'label', maxIter=10)\n",
    "\n",
    "lrModel_final = lr.fit(loanDF)\n",
    "\n",
    "predictions_final = lrModel_final.transform(testDF2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_final.select('id', 'prediction').toPandas().to_csv('../data/submission_final.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MySparkContext.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "432px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
